{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package reuters to /home/nimmi/nltk_data...\n",
      "[nltk_data]   Package reuters is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import *\n",
    "import string\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from util import *\n",
    "from reg_utils import *\n",
    "\n",
    "import sys\n",
    "assert sys.version_info[0]==3\n",
    "assert sys.version_info[1] >= 5\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.test.utils import datapath\n",
    "import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [10, 5]\n",
    "import nltk\n",
    "nltk.download('reuters')\n",
    "from nltk.corpus import reuters\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "import scipy as sp\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.decomposition import PCA\n",
    "import datetime\n",
    "from collections import *\n",
    "from util import *\n",
    "\n",
    "\n",
    "START_TOKEN = '<START>'\n",
    "END_TOKEN = '<END>'\n",
    "SEPARATOR = \"&#xD;&#xA;\"\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "def reduce_to_k_dim(M, k=2):\n",
    "    \"\"\" Reduce a co-occurence count matrix of dimensionality (num_corpus_words, num_corpus_words)\n",
    "        to a matrix of dimensionality (num_corpus_words, k) using the following SVD function from Scikit-Learn:\n",
    "            - http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html\n",
    "    \n",
    "        Params:\n",
    "            M (numpy matrix of shape (number of unique words in the corpus , number of unique words in the corpus)): co-occurence matrix of word counts\n",
    "            k (int): embedding size of each word after dimension reduction\n",
    "        Return:\n",
    "            M_reduced (numpy matrix of shape (number of corpus words, k)): matrix of k-dimensioal word embeddings.\n",
    "                    In terms of the SVD from math class, this actually returns U * S\n",
    "    \"\"\"    \n",
    "    n_iters = 10     # Use this parameter in your call to `TruncatedSVD`\n",
    "    M_reduced = None\n",
    "    print(\"Running Truncated SVD over %i words...\" % (M.shape[0]))\n",
    "    \n",
    "    # ------------------\n",
    "    # Write your implementation here.\n",
    "        \n",
    "    svd = TruncatedSVD(n_components=k, n_iter=n_iters)\n",
    "    M_reduced = svd.fit_transform(M)\n",
    "    \n",
    "    # ------------------\n",
    "\n",
    "    print(\"Done.\")\n",
    "    return M_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Truncated SVD over 1818 words...\n",
      "Done.\n",
      "Running Truncated SVD over 818 words...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "ROOT = \"/home/nimmi/Documents/Victoria/RA/re-idioms/questions/notebook/classifier-codes/\"\n",
    "\n",
    "MCO = pd.read_csv(ROOT+\"pytorch/df_M_co_occurrence.csv\", index_col = 0)\n",
    "MCO_titles = pd.read_csv(ROOT+\"pytorch/df_M_co_occurrence_titles.csv\", index_col = 0)\n",
    "\n",
    "with open(ROOT+'pytorch/json_word2Ind_co_occurrence.json') as f:\n",
    "      W2ICO = json.load(f)\n",
    "with open(ROOT+'pytorch/json_word2Ind_co_occurrence_titles.json') as f:\n",
    "      W2ICO_titles = json.load(f)\n",
    "        \n",
    "#For code snippets\n",
    "        \n",
    "M_reduced_co_occurrence = reduce_to_k_dim(MCO, k=50)\n",
    "\n",
    "# Rescale (normalize) the rows to make them each of unit-length\n",
    "M_lengths = np.linalg.norm(M_reduced_co_occurrence, axis=1)\n",
    "M_normalized = M_reduced_co_occurrence / M_lengths[:, np.newaxis] # broadcasting\n",
    "w2v_embedding = {w: M_normalized[W2ICO[w]] for w in W2ICO}\n",
    "\n",
    "\n",
    "#For titles\n",
    "\n",
    "M_reduced_co_occurrence_titles = reduce_to_k_dim(MCO_titles, k=50)\n",
    "\n",
    "# Rescale (normalize) the rows to make them each of unit-length\n",
    "M_lengths_titles = np.linalg.norm(M_reduced_co_occurrence_titles, axis=1)\n",
    "M_normalized_titles = M_reduced_co_occurrence_titles / M_lengths_titles[:, np.newaxis] # broadcasting\n",
    "w2v_embedding_titles = {w: M_normalized_titles[W2ICO_titles[w]] for w in W2ICO_titles}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_code_snippet(code):\n",
    "    \n",
    "    _code = re.sub('[\\(]', ' ( ', code)\n",
    "    _code = re.sub('[\\)]', ' ) ', _code)\n",
    "    _code = re.sub('[\\.]', ' . ', _code)\n",
    "    _code = re.sub('[\\_]', ' ', _code)\n",
    "    _code = re.sub('[\\+]', ' + ', _code)\n",
    "    _code = re.sub('[\\-]', ' - ', _code)\n",
    "    _code = re.sub('[\\*]', ' * ', _code)\n",
    "    _code = re.sub('[\\{]', ' { ', _code)\n",
    "    _code = re.sub('[\\}]', ' } ', _code)\n",
    "    _code = re.sub('[\\&]', ' & ', _code)\n",
    "    _code = re.sub('[\\|]', ' | ', _code)\n",
    "    _code = re.sub('[\\[]', ' [ ', _code)\n",
    "    _code = re.sub('[\\]]', ' ] ', _code)\n",
    "    _code = re.sub('[=]', ' = ', _code)\n",
    "    _code = re.sub('[>][^=]', ' > ', _code)\n",
    "    _code = re.sub('[<][^=]', ' < ', _code)\n",
    "    _code = re.sub('[>][=]', ' >= ', _code)\n",
    "    _code = re.sub('[<][=]', ' <= ', _code)\n",
    "    _code = re.sub('/', ' / ', _code)\n",
    "    #_code = re.sub('\\\\', ' \\ ', _code)\n",
    "    _code = re.sub(',', ' , ', _code)\n",
    "    _code = re.sub(':', ' : ', _code)\n",
    "    _code = re.sub('!', ' ! ', _code)\n",
    "    _code = re.sub(';', '', _code)\n",
    "    _code = re.sub('[\\s]+', ' ', _code)\n",
    "    \n",
    "    return _code\n",
    "    \n",
    "def remove_rare_words(corpus, limit):\n",
    "    counts = Counter()\n",
    "    for row in corpus:\n",
    "        counts.update(row)\n",
    "    \n",
    "    #deleting infrequent words\n",
    "    print(\"num_words before:\",len(counts.keys()))\n",
    "    for word in list(counts):\n",
    "        if counts[word] <= limit:\n",
    "            del counts[word]\n",
    "    print(\"num_words after:\",len(counts.keys()))\n",
    "    _corpus = []\n",
    "    \n",
    "    for words in corpus:\n",
    "        _words = []\n",
    "        for word in words:\n",
    "            count = counts[word]\n",
    "            \n",
    "            if count == 0:\n",
    "                continue\n",
    "            _words.append(word)\n",
    "        _corpus.append(_words)\n",
    "        \n",
    "    return _corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'PostTypeId', 'AcceptedAnswerId', 'ParentId', 'CreationDate',\n",
       "       'DeletionDate', 'Score', 'ViewCount', 'Body', 'OwnerUserId',\n",
       "       'OwnerDisplayName', 'LastEditorUserId', 'LastEditorDisplayName',\n",
       "       'LastEditDate', 'LastActivityDate', 'Title', 'Tags', 'AnswerCount',\n",
       "       'CommentCount', 'FavoriteCount', 'ClosedDate', 'CommunityOwnedDate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "js = pd.read_csv(ROOT+\"javascriptTop1000.csv\")\n",
    "js.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_corpus():\n",
    "\n",
    "    snippets = pd.read_csv(ROOT+\"top1000_snippets_v2.csv\")\n",
    "    code_snippets = snippets[snippets['PostBlockTypeId']==2]   \n",
    "    \n",
    "    js = pd.read_csv(ROOT+\"javascriptTop1000.csv\")\n",
    "    python = pd.read_csv(ROOT+\"pythonTop1000.csv\")\n",
    "    java = pd.read_csv(ROOT+\"javaTop1000.csv\")\n",
    "    questions = js.append(python, ignore_index=True).append(java, ignore_index=True)\n",
    "    print(questions.columns)\n",
    "    \n",
    "    code_snippets['is_idiomatic'] = 0\n",
    "    #--------------------------------------------------------------------------------------------\n",
    "    \n",
    "    #If only javascript\n",
    "    #js = pd.read_csv(ROOT+\"javascriptTop1000.csv\")\n",
    "    #code_snippets = code_snippets[code_snippets['ParentId'].map(lambda x: x in js['Id'].values)]\n",
    "\n",
    "    golden_set = pd.read_csv(\"golden_set_edited.csv\", index_col= 0)\n",
    "    golden_set = golden_set[(golden_set[\"IsIdiom\"]==1)|(golden_set[\"IsIdiom\"]==0)]\n",
    "\n",
    "    golden_set_indices = golden_set.index\n",
    "    code_snippets['is_golden']=0\n",
    "    code_snippets.loc[golden_set_indices,'is_golden']=1\n",
    "    \n",
    "    golden_idiom_set_indices = golden_set[golden_set['IsIdiom']==1].index\n",
    "    code_snippets['is_golden_idiom']=0\n",
    "    code_snippets.loc[golden_idiom_set_indices,'is_golden_idiom']=1\n",
    "\n",
    "    code_snippet_0 = code_snippets[code_snippets['is_golden']==0]\n",
    "    code_snippet_1 = code_snippets[code_snippets['is_golden']==1]\n",
    "    code_snippet_1['is_idiomatic'] = code_snippet_1['is_golden_idiom']    \n",
    "    #------\n",
    "    \n",
    "    code_snippets = code_snippet_0.copy()\n",
    "    code_LOC = code_snippets['Content'].map(lambda code: len(code.split(\"&#xD;&#xA;\")))\n",
    "    code_snippets['LOC'] = code_LOC\n",
    "    _code_snippets = code_snippets[code_snippets.Content.str.match('.*class')==False]\n",
    "    _code_snippets = _code_snippets[_code_snippets.Content.str.match('.*((function)|(def)|(return)|(void))')==False]\n",
    "    one_liners = _code_snippets[_code_snippets['Content'].map(lambda x: len(x.split('&#xD;&#xA;'))==1)]\n",
    "    _code_snippets = _code_snippets[_code_snippets['Content'].map(lambda x: len(x.split('&#xD;&#xA;'))!=1)]\n",
    "    loc_threshold = 20\n",
    "    _code_snippets = _code_snippets[_code_snippets['LOC']<=loc_threshold]\n",
    "    regex = '.*([a-zA-Z]*\\.)*[a-zA-Z]*\\(.*\\)'\n",
    "    function_call_one_liners = one_liners[one_liners.Content.str.match(regex)==True]\n",
    "    other_one_liners = one_liners[one_liners.Content.str.match(regex)==False]\n",
    "    code_snippets_with_placeholders = _code_snippets[_code_snippets.Content.str.match('.*//*(?i)((code)|(here)|(your))+')]['Content']\n",
    "\n",
    "    \n",
    "\n",
    "    function_call_one_liners_code_snippets_indices = function_call_one_liners.index\n",
    "    code_snippets['is_idiomatic'][function_call_one_liners_code_snippets_indices] = -2\n",
    "    other_one_liners_code_snippets_indices = other_one_liners.index\n",
    "    code_snippets['is_idiomatic'][other_one_liners_code_snippets_indices] = -3\n",
    "    idiomatic_code_snippets_indices = _code_snippets.index\n",
    "    code_snippets['is_idiomatic'][idiomatic_code_snippets_indices] = 1\n",
    "    code_snippets.loc[code_snippets[\"Content\"].map(is_commandline),'is_idiomatic']=0\n",
    "    code_snippets.loc[code_snippets[\"Content\"].map(is_markup_language),'is_idiomatic']=0\n",
    "    code_snippets.loc[code_snippets[\"Content\"].map(lambda x: len(x.split(\"&#xD;&#xA;\"))>20),'is_idiomatic']=0\n",
    "    code_snippets.loc[code_snippets[\"Content\"].map(is_method),'is_idiomatic'] = 0\n",
    "    \n",
    "    \n",
    "    code_snippets[\"Edited_Content\"] = code_snippets[\"Content\"].map(remove_print_statements)\n",
    "    code_snippets[\"Edited_Content\"] = code_snippets[\"Edited_Content\"].map(remove_one_line_comments_1)\n",
    "    code_snippets[\"Edited_Content\"] = code_snippets[\"Edited_Content\"].map(remove_one_line_comments_2)\n",
    "    code_snippets[\"Edited_Content\"] = code_snippets[\"Edited_Content\"].map(remove_js_object_declarations)\n",
    "    code_snippets.loc[code_snippets[\"Edited_Content\"].map(is_string_null),'is_idiomatic']=0\n",
    "    code_snippets.loc[code_snippets[\"Edited_Content\"].map(is_one_line),'is_idiomatic']=0\n",
    "\n",
    "\n",
    "    code_snippets = code_snippets[code_snippets['is_idiomatic']>=0]\n",
    "    \n",
    "    train_code_snippets_indices = code_snippets.index\n",
    "    is_idiomatic = code_snippets['is_idiomatic'].values    \n",
    "    \n",
    "    code_snippet_0 = code_snippet_0.loc[train_code_snippets_indices]\n",
    "    code_snippet_0['is_idiomatic'] = is_idiomatic\n",
    "\n",
    "    #------\n",
    "\n",
    "    code_snippets = code_snippet_0.append(code_snippet_1, ignore_index=True)\n",
    " \n",
    "    #--------------------------------------------------------------------------------------------\n",
    "    \n",
    "    code_snippets['text'] = code_snippets['Content'].map(remove_print_statements)\n",
    "    code_snippets['text'] = code_snippets['text'].map(remove_one_line_comments_1)\n",
    "    code_snippets['text'] = code_snippets['text'].map(remove_one_line_comments_2)\n",
    "    code_snippets['text'] = code_snippets['text'].map(lambda x: x.strip().replace(SEPARATOR,\" \"))\n",
    "    code_snippets['text'] = code_snippets['text'].map(process_code_snippet)\n",
    "    \n",
    "    #--------------------------------------------------------------------------------------------\n",
    "    \n",
    "    \n",
    "    corpus = [[START_TOKEN] + [w.lower() for w in c.split(\" \")] + [END_TOKEN] for c in code_snippets['text'].values]\n",
    "    #corpus = remove_rare_words(corpus,30)\n",
    "    \n",
    "    code_snippets['tokens'] = corpus\n",
    "    \n",
    "    \n",
    "    print(\"b4\")\n",
    "    print(len(code_snippets))\n",
    "    print(\"questions\")\n",
    "    print(questions.head(2))\n",
    "    print(\"code_snippets\")\n",
    "    print(code_snippets['ParentId'])\n",
    "    \n",
    "    code_snippets = pd.merge(code_snippets, questions, left_on='ParentId', right_on='Id')\n",
    "    \n",
    "    print(\"after\")\n",
    "    print(len(code_snippets))\n",
    "\n",
    "    title_corpus = [[START_TOKEN] + [w.lower() for w in c.split(\" \")] + [END_TOKEN] for c in code_snippets['Title'].values]\n",
    "    #title_corpus = remove_rare_words(title_corpus,3)\n",
    "    \n",
    "    code_snippets['title_tokens'] = title_corpus\n",
    "    \n",
    "    code_snippets['QuestionScore']=code_snippets[\"Score\"]\n",
    "    code_snippets = code_snippets.drop(['Score'], axis=1)\n",
    "    \n",
    "    \n",
    "    return corpus, code_snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2184\n",
      "339\n",
      "1571\n",
      "89\n"
     ]
    }
   ],
   "source": [
    "golden_set = pd.read_csv(\"golden_set_edited.csv\", index_col= 0)\n",
    "\n",
    "print(len(golden_set))\n",
    "print(len(golden_set[golden_set[\"IsIdiom\"]==1]))\n",
    "print(len(golden_set[golden_set[\"IsIdiom\"]==0]))\n",
    "print(len(golden_set[golden_set[\"IsIdiom\"]==-1]))\n",
    "vague = golden_set[golden_set[\"IsIdiom\"]==-1]['Content']\n",
    "\n",
    "golden_set = golden_set[(golden_set[\"IsIdiom\"]==1)|(golden_set[\"IsIdiom\"]==0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Id', 'PostTypeId', 'AcceptedAnswerId', 'ParentId', 'CreationDate',\n",
      "       'DeletionDate', 'Score', 'ViewCount', 'Body', 'OwnerUserId',\n",
      "       'OwnerDisplayName', 'LastEditorUserId', 'LastEditorDisplayName',\n",
      "       'LastEditDate', 'LastActivityDate', 'Title', 'Tags', 'AnswerCount',\n",
      "       'CommentCount', 'FavoriteCount', 'ClosedDate', 'CommunityOwnedDate'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nimmi/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n",
      "/home/nimmi/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/nimmi/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:965: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "/home/nimmi/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/nimmi/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/nimmi/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/nimmi/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/nimmi/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b4\n",
      "26029\n",
      "questions\n",
      "       Id  PostTypeId  AcceptedAnswerId  ParentId             CreationDate  \\\n",
      "0  679915           1        32108184.0       NaN  2009-03-25T01:39:45.860   \n",
      "1  263965           1          264037.0       NaN  2008-11-05T00:13:08.963   \n",
      "\n",
      "   DeletionDate  Score  ViewCount  Body  OwnerUserId  ...  \\\n",
      "0           NaN   2730    1949580   NaN      64784.0  ...   \n",
      "1           NaN   2328    1808485   NaN       4599.0  ...   \n",
      "\n",
      "  LastEditorDisplayName             LastEditDate         LastActivityDate  \\\n",
      "0                   NaN  2019-06-04T21:49:39.640  2019-11-15T18:06:32.117   \n",
      "1                   NaN                      NaN  2019-11-05T16:37:01.873   \n",
      "\n",
      "                                               Title          Tags  \\\n",
      "0      How do I test for an empty JavaScript object?  <javascript>   \n",
      "1  How can I convert a string to boolean in JavaS...  <javascript>   \n",
      "\n",
      "  AnswerCount CommentCount  FavoriteCount  ClosedDate       CommunityOwnedDate  \n",
      "0          48            1          549.0         NaN                      NaN  \n",
      "1          75           10          324.0         NaN  2013-06-23T19:39:41.573  \n",
      "\n",
      "[2 rows x 22 columns]\n",
      "code_snippets\n",
      "0            1829\n",
      "1            1829\n",
      "2            1829\n",
      "3            1829\n",
      "4            1829\n",
      "           ...   \n",
      "26024    14636536\n",
      "26025     6040515\n",
      "26026      359788\n",
      "26027     9439725\n",
      "26028     4059147\n",
      "Name: ParentId, Length: 26029, dtype: int64\n",
      "after\n",
      "26029\n"
     ]
    }
   ],
   "source": [
    "corpus, codes = read_corpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ParentId_x', 'PostId', 'PostHistoryId', 'LocalId', 'PostBlockTypeId',\n",
       "       'Length', 'LineCount', 'Content', 'is_idiomatic', 'is_golden',\n",
       "       'is_golden_idiom', 'text', 'tokens', 'Id', 'PostTypeId',\n",
       "       'AcceptedAnswerId', 'ParentId_y', 'CreationDate', 'DeletionDate',\n",
       "       'ViewCount', 'Body', 'OwnerUserId', 'OwnerDisplayName',\n",
       "       'LastEditorUserId', 'LastEditorDisplayName', 'LastEditDate',\n",
       "       'LastActivityDate', 'Title', 'Tags', 'AnswerCount', 'CommentCount',\n",
       "       'FavoriteCount', 'ClosedDate', 'CommunityOwnedDate', 'title_tokens',\n",
       "       'QuestionScore'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codes.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* top1000_answers.csv lists all answers together with their score and whether they are the accepted answer.\n",
    "\n",
    "* top1000_answers_score_vs_accepted.csv lists the answers with the highest score and whether they are the accepted answers. If there are two answers with the same score and one of them is accepted, only the accepted one is shown. This list suggests that we should consider both the accepted answers as well as the answers with the highest score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ParentId', 'AcceptedAnswerScore'], dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ROOT_DATA = \"/home/nimmi/Documents/Victoria/RA/re-idioms/questions/data/\"\n",
    "data = pd.read_csv(ROOT_DATA+\"top1000_answers.csv\")\n",
    "accepted_answer_score = data[data['IsAcceptedAnswer']][['Score', 'ParentId']]\n",
    "accepted_answer_score['AcceptedAnswerScore'] = accepted_answer_score['Score']\n",
    "accepted_answer_score = accepted_answer_score[['ParentId','AcceptedAnswerScore']]\n",
    "accepted_answer_score.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = pd.merge(codes, accepted_answer_score, left_on='ParentId_x', right_on='ParentId')\n",
    "#_merged_data = merged_data[merged_data['AcceptedAnswerScore']<=merged_data['Score']]\n",
    "code_bkp = codes.copy()\n",
    "codes = merged_data \n",
    "#codes = codes.loc[codes['ParentId_x'].map(lambda x: x in _merged_data['ParentId'].values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ParentId_x', 'PostId', 'PostHistoryId', 'LocalId', 'PostBlockTypeId',\n",
       "       'Length', 'LineCount', 'Content', 'is_idiomatic', 'is_golden',\n",
       "       'is_golden_idiom', 'text', 'tokens', 'Id', 'PostTypeId',\n",
       "       'AcceptedAnswerId', 'ParentId_y', 'CreationDate', 'DeletionDate',\n",
       "       'ViewCount', 'Body', 'OwnerUserId', 'OwnerDisplayName',\n",
       "       'LastEditorUserId', 'LastEditorDisplayName', 'LastEditDate',\n",
       "       'LastActivityDate', 'Title', 'Tags', 'AnswerCount', 'CommentCount',\n",
       "       'FavoriteCount', 'ClosedDate', 'CommunityOwnedDate', 'title_tokens',\n",
       "       'QuestionScore', 'ParentId', 'AcceptedAnswerScore'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codes.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22255"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ParentId', 'PostId', 'IsAcceptedAnswer', 'Score'], dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = pd.merge(codes, data[['PostId','Score']], left_on='PostId', right_on='PostId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19426"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ParentId_x', 'PostId', 'PostHistoryId', 'LocalId', 'PostBlockTypeId',\n",
       "       'Length', 'LineCount', 'Content', 'is_idiomatic', 'is_golden',\n",
       "       'is_golden_idiom', 'text', 'tokens', 'Id', 'PostTypeId',\n",
       "       'AcceptedAnswerId', 'ParentId_y', 'CreationDate', 'DeletionDate',\n",
       "       'ViewCount', 'Body', 'OwnerUserId', 'OwnerDisplayName',\n",
       "       'LastEditorUserId', 'LastEditorDisplayName', 'LastEditDate',\n",
       "       'LastActivityDate', 'Title', 'Tags', 'AnswerCount', 'CommentCount',\n",
       "       'FavoriteCount', 'ClosedDate', 'CommunityOwnedDate', 'title_tokens',\n",
       "       'QuestionScore', 'ParentId', 'AcceptedAnswerScore', 'Score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codes.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AcceptedAnswerScore</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>305</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>305</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>305</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19419</th>\n",
       "      <td>580</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19422</th>\n",
       "      <td>538</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19423</th>\n",
       "      <td>538</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19424</th>\n",
       "      <td>538</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19425</th>\n",
       "      <td>151</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15847 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       AcceptedAnswerScore  Score\n",
       "0                        9      9\n",
       "2                        9      4\n",
       "3                      305      4\n",
       "4                      305      4\n",
       "5                      305      4\n",
       "...                    ...    ...\n",
       "19419                  580    100\n",
       "19422                  538     89\n",
       "19423                  538     89\n",
       "19424                  538     89\n",
       "19425                  151     77\n",
       "\n",
       "[15847 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codes[codes['PostId']!=codes['AcceptedAnswerId']][['AcceptedAnswerScore', 'Score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.378410377844126"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "codes['code_length'] = codes['Content'].apply(lambda x: len(re.sub(\"[\\s]+\",\" \",x).strip().split()))\n",
    "np.mean(codes['code_length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection(lst1, lst2): \n",
    "    lst3 = [value for value in lst1 if value in lst2] \n",
    "    return lst3 \n",
    "\n",
    "\n",
    "def encode_sentence(tokens, vocab2index, N=100):\n",
    "    \n",
    "    list_vocab = [x for x in vocab2index.keys()]\n",
    "    tokens = intersection(tokens, list_vocab)\n",
    "    encoded = np.zeros(N, dtype=int)\n",
    "    enc1 = np.array([vocab2index.get(word) for word in tokens])\n",
    "    length = min(N, len(enc1))\n",
    "    try:\n",
    "        encoded[:length] = enc1[:length]\n",
    "    except:\n",
    "        print(length)\n",
    "\n",
    "    return encoded, length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [[322, 935, 1611, 935, 1488, 935, 935, 651, 85...\n",
       "1    [[322, 935, 388, 323, 195, 189, 190, 0, 321, 0...\n",
       "Name: token_numbers, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab2index=W2ICO\n",
    "codes['token_numbers'] = codes['tokens'].apply(lambda tokens: np.array(encode_sentence(tokens,vocab2index )))\n",
    "\n",
    "vocab2index=W2ICO_titles\n",
    "codes['title_token_numbers'] = codes['title_tokens'].apply(lambda tokens: np.array(encode_sentence(tokens,vocab2index, N=20)))\n",
    "codes['token_numbers'] .head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1598"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(codes[codes['is_golden']==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17828"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_val_length = len(codes[codes['is_golden']==0])\n",
    "train_val_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ParentId_x</th>\n",
       "      <th>PostId</th>\n",
       "      <th>PostHistoryId</th>\n",
       "      <th>LocalId</th>\n",
       "      <th>PostBlockTypeId</th>\n",
       "      <th>Length</th>\n",
       "      <th>LineCount</th>\n",
       "      <th>Content</th>\n",
       "      <th>is_idiomatic</th>\n",
       "      <th>is_golden</th>\n",
       "      <th>...</th>\n",
       "      <th>ClosedDate</th>\n",
       "      <th>CommunityOwnedDate</th>\n",
       "      <th>title_tokens</th>\n",
       "      <th>QuestionScore</th>\n",
       "      <th>ParentId</th>\n",
       "      <th>AcceptedAnswerScore</th>\n",
       "      <th>Score</th>\n",
       "      <th>code_length</th>\n",
       "      <th>token_numbers</th>\n",
       "      <th>title_token_numbers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>94037</td>\n",
       "      <td>9539389</td>\n",
       "      <td>156966773</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1547</td>\n",
       "      <td>22</td>\n",
       "      <td>{&amp;#xD;&amp;#xA;    \"31\": \"\",      \"32\": \" \",  ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[&lt;START&gt;, convert, character, to, ascii, code,...</td>\n",
       "      <td>900</td>\n",
       "      <td>94037</td>\n",
       "      <td>1417</td>\n",
       "      <td>373</td>\n",
       "      <td>216</td>\n",
       "      <td>[[322, 0, 1811, 319, 3, 193, 319, 2, 2, 193, 3...</td>\n",
       "      <td>[[35, 188, 145, 730, 78, 157, 363, 408, 34, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>94037</td>\n",
       "      <td>22173154</td>\n",
       "      <td>125913554</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>function ascii (a) { return a.charCodeAt(0...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[&lt;START&gt;, convert, character, to, ascii, code,...</td>\n",
       "      <td>900</td>\n",
       "      <td>94037</td>\n",
       "      <td>1417</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>[[322, 834, 418, 189, 349, 190, 1811, 1436, 34...</td>\n",
       "      <td>[[35, 188, 145, 730, 78, 157, 363, 408, 34, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>94037</td>\n",
       "      <td>22173154</td>\n",
       "      <td>125913554</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>152</td>\n",
       "      <td>6</td>\n",
       "      <td>$(window).keypress(function(event) {&amp;#xD;&amp;...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[&lt;START&gt;, convert, character, to, ascii, code,...</td>\n",
       "      <td>900</td>\n",
       "      <td>94037</td>\n",
       "      <td>1417</td>\n",
       "      <td>23</td>\n",
       "      <td>14</td>\n",
       "      <td>[[322, 96, 189, 1772, 190, 195, 189, 834, 189,...</td>\n",
       "      <td>[[35, 188, 145, 730, 78, 157, 363, 408, 34, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>94037</td>\n",
       "      <td>30887763</td>\n",
       "      <td>206618355</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>87</td>\n",
       "      <td>4</td>\n",
       "      <td>'Foobar'&amp;#xD;&amp;#xA;      .split('')&amp;#xD;&amp;#x...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[&lt;START&gt;, convert, character, to, ascii, code,...</td>\n",
       "      <td>900</td>\n",
       "      <td>94037</td>\n",
       "      <td>1417</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>[[322, 195, 1547, 189, 109, 190, 195, 1110, 18...</td>\n",
       "      <td>[[35, 188, 145, 730, 78, 157, 363, 408, 34, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>94037</td>\n",
       "      <td>30887763</td>\n",
       "      <td>206618355</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>113</td>\n",
       "      <td>3</td>\n",
       "      <td>[...'Foobar']&amp;#xD;&amp;#xA;      .map(char =&gt; ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[&lt;START&gt;, convert, character, to, ascii, code,...</td>\n",
       "      <td>900</td>\n",
       "      <td>94037</td>\n",
       "      <td>1417</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>[[322, 0, 335, 195, 195, 195, 345, 195, 1110, ...</td>\n",
       "      <td>[[35, 188, 145, 730, 78, 157, 363, 408, 34, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19421</th>\n",
       "      <td>12797118</td>\n",
       "      <td>12797135</td>\n",
       "      <td>190177330</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>5</td>\n",
       "      <td>function myFunc(a,b) {&amp;#xD;&amp;#xA;      b = ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2012-10-10T11:48:27.567</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[&lt;START&gt;, how, can, i, declare, optional, func...</td>\n",
       "      <td>289</td>\n",
       "      <td>12797118</td>\n",
       "      <td>538</td>\n",
       "      <td>538</td>\n",
       "      <td>21</td>\n",
       "      <td>[[322, 834, 1163, 189, 349, 193, 437, 190, 181...</td>\n",
       "      <td>[[35, 346, 134, 350, 210, 528, 318, 546, 363, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19422</th>\n",
       "      <td>12797118</td>\n",
       "      <td>12797265</td>\n",
       "      <td>211809687</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>509</td>\n",
       "      <td>15</td>\n",
       "      <td>function myfunc(a, b)&amp;#xD;&amp;#xA;    {&amp;#xD;&amp;...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2012-10-10T11:48:27.567</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[&lt;START&gt;, how, can, i, declare, optional, func...</td>\n",
       "      <td>289</td>\n",
       "      <td>12797118</td>\n",
       "      <td>538</td>\n",
       "      <td>89</td>\n",
       "      <td>86</td>\n",
       "      <td>[[322, 834, 1163, 189, 349, 193, 437, 190, 181...</td>\n",
       "      <td>[[35, 346, 134, 350, 210, 528, 318, 546, 363, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19423</th>\n",
       "      <td>12797118</td>\n",
       "      <td>12797265</td>\n",
       "      <td>211809687</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>260</td>\n",
       "      <td>10</td>\n",
       "      <td>function myfunc(a)&amp;#xD;&amp;#xA;    {&amp;#xD;&amp;#xA...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2012-10-10T11:48:27.567</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[&lt;START&gt;, how, can, i, declare, optional, func...</td>\n",
       "      <td>289</td>\n",
       "      <td>12797118</td>\n",
       "      <td>538</td>\n",
       "      <td>89</td>\n",
       "      <td>38</td>\n",
       "      <td>[[322, 834, 1163, 189, 349, 190, 1811, 1746, 4...</td>\n",
       "      <td>[[35, 346, 134, 350, 210, 528, 318, 546, 363, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19424</th>\n",
       "      <td>12797118</td>\n",
       "      <td>12797265</td>\n",
       "      <td>211809687</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>86</td>\n",
       "      <td>2</td>\n",
       "      <td>b === void 0;&amp;#xD;&amp;#xA;    typeof b === 'u...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2012-10-10T11:48:27.567</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[&lt;START&gt;, how, can, i, declare, optional, func...</td>\n",
       "      <td>289</td>\n",
       "      <td>12797118</td>\n",
       "      <td>538</td>\n",
       "      <td>89</td>\n",
       "      <td>14</td>\n",
       "      <td>[[322, 437, 323, 323, 323, 1755, 197, 1698, 43...</td>\n",
       "      <td>[[35, 346, 134, 350, 210, 528, 318, 546, 363, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19425</th>\n",
       "      <td>33854103</td>\n",
       "      <td>50454071</td>\n",
       "      <td>173891138</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1236</td>\n",
       "      <td>35</td>\n",
       "      <td>BTOA(1) \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t  BTOA(1)&amp;#xD;...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[&lt;START&gt;, why, were, javascript, `atob()`, and...</td>\n",
       "      <td>231</td>\n",
       "      <td>33854103</td>\n",
       "      <td>151</td>\n",
       "      <td>77</td>\n",
       "      <td>170</td>\n",
       "      <td>[[322, 189, 215, 190, 189, 215, 190, 1176, 194...</td>\n",
       "      <td>[[35, 791, 408, 61, 490, 436, 34, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1598 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ParentId_x    PostId  PostHistoryId  LocalId  PostBlockTypeId  Length  \\\n",
       "55          94037   9539389      156966773        6                2    1547   \n",
       "59          94037  22173154      125913554        2                2      55   \n",
       "60          94037  22173154      125913554        6                2     152   \n",
       "61          94037  30887763      206618355        2                2      87   \n",
       "62          94037  30887763      206618355        4                2     113   \n",
       "...           ...       ...            ...      ...              ...     ...   \n",
       "19421    12797118  12797135      190177330        4                2      99   \n",
       "19422    12797118  12797265      211809687        2                2     509   \n",
       "19423    12797118  12797265      211809687        4                2     260   \n",
       "19424    12797118  12797265      211809687        6                2      86   \n",
       "19425    33854103  50454071      173891138        2                2    1236   \n",
       "\n",
       "       LineCount                                            Content  \\\n",
       "55            22      {&#xD;&#xA;    \"31\": \"\",      \"32\": \" \",  ...   \n",
       "59             2      function ascii (a) { return a.charCodeAt(0...   \n",
       "60             6      $(window).keypress(function(event) {&#xD;&...   \n",
       "61             4      'Foobar'&#xD;&#xA;      .split('')&#xD;&#x...   \n",
       "62             3      [...'Foobar']&#xD;&#xA;      .map(char => ...   \n",
       "...          ...                                                ...   \n",
       "19421          5      function myFunc(a,b) {&#xD;&#xA;      b = ...   \n",
       "19422         15      function myfunc(a, b)&#xD;&#xA;    {&#xD;&...   \n",
       "19423         10      function myfunc(a)&#xD;&#xA;    {&#xD;&#xA...   \n",
       "19424          2      b === void 0;&#xD;&#xA;    typeof b === 'u...   \n",
       "19425         35      BTOA(1) \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t  BTOA(1)&#xD;...   \n",
       "\n",
       "       is_idiomatic  is_golden  ...               ClosedDate  \\\n",
       "55                0          1  ...                      NaN   \n",
       "59                0          1  ...                      NaN   \n",
       "60                0          1  ...                      NaN   \n",
       "61                0          1  ...                      NaN   \n",
       "62                0          1  ...                      NaN   \n",
       "...             ...        ...  ...                      ...   \n",
       "19421             0          1  ...  2012-10-10T11:48:27.567   \n",
       "19422             0          1  ...  2012-10-10T11:48:27.567   \n",
       "19423             0          1  ...  2012-10-10T11:48:27.567   \n",
       "19424             1          1  ...  2012-10-10T11:48:27.567   \n",
       "19425             0          1  ...                      NaN   \n",
       "\n",
       "      CommunityOwnedDate                                       title_tokens  \\\n",
       "55                   NaN  [<START>, convert, character, to, ascii, code,...   \n",
       "59                   NaN  [<START>, convert, character, to, ascii, code,...   \n",
       "60                   NaN  [<START>, convert, character, to, ascii, code,...   \n",
       "61                   NaN  [<START>, convert, character, to, ascii, code,...   \n",
       "62                   NaN  [<START>, convert, character, to, ascii, code,...   \n",
       "...                  ...                                                ...   \n",
       "19421                NaN  [<START>, how, can, i, declare, optional, func...   \n",
       "19422                NaN  [<START>, how, can, i, declare, optional, func...   \n",
       "19423                NaN  [<START>, how, can, i, declare, optional, func...   \n",
       "19424                NaN  [<START>, how, can, i, declare, optional, func...   \n",
       "19425                NaN  [<START>, why, were, javascript, `atob()`, and...   \n",
       "\n",
       "       QuestionScore  ParentId  AcceptedAnswerScore  Score code_length  \\\n",
       "55               900     94037                 1417    373         216   \n",
       "59               900     94037                 1417     23           7   \n",
       "60               900     94037                 1417     23          14   \n",
       "61               900     94037                 1417     19           4   \n",
       "62               900     94037                 1417     19          10   \n",
       "...              ...       ...                  ...    ...         ...   \n",
       "19421            289  12797118                  538    538          21   \n",
       "19422            289  12797118                  538     89          86   \n",
       "19423            289  12797118                  538     89          38   \n",
       "19424            289  12797118                  538     89          14   \n",
       "19425            231  33854103                  151     77         170   \n",
       "\n",
       "                                           token_numbers  \\\n",
       "55     [[322, 0, 1811, 319, 3, 193, 319, 2, 2, 193, 3...   \n",
       "59     [[322, 834, 418, 189, 349, 190, 1811, 1436, 34...   \n",
       "60     [[322, 96, 189, 1772, 190, 195, 189, 834, 189,...   \n",
       "61     [[322, 195, 1547, 189, 109, 190, 195, 1110, 18...   \n",
       "62     [[322, 0, 335, 195, 195, 195, 345, 195, 1110, ...   \n",
       "...                                                  ...   \n",
       "19421  [[322, 834, 1163, 189, 349, 193, 437, 190, 181...   \n",
       "19422  [[322, 834, 1163, 189, 349, 193, 437, 190, 181...   \n",
       "19423  [[322, 834, 1163, 189, 349, 190, 1811, 1746, 4...   \n",
       "19424  [[322, 437, 323, 323, 323, 1755, 197, 1698, 43...   \n",
       "19425  [[322, 189, 215, 190, 189, 215, 190, 1176, 194...   \n",
       "\n",
       "                                     title_token_numbers  \n",
       "55     [[35, 188, 145, 730, 78, 157, 363, 408, 34, 0,...  \n",
       "59     [[35, 188, 145, 730, 78, 157, 363, 408, 34, 0,...  \n",
       "60     [[35, 188, 145, 730, 78, 157, 363, 408, 34, 0,...  \n",
       "61     [[35, 188, 145, 730, 78, 157, 363, 408, 34, 0,...  \n",
       "62     [[35, 188, 145, 730, 78, 157, 363, 408, 34, 0,...  \n",
       "...                                                  ...  \n",
       "19421  [[35, 346, 134, 350, 210, 528, 318, 546, 363, ...  \n",
       "19422  [[35, 346, 134, 350, 210, 528, 318, 546, 363, ...  \n",
       "19423  [[35, 346, 134, 350, 210, 528, 318, 546, 363, ...  \n",
       "19424  [[35, 346, 134, 350, 210, 528, 318, 546, 363, ...  \n",
       "19425  [[35, 791, 408, 61, 490, 436, 34, 0, 0, 0, 0, ...  \n",
       "\n",
       "[1598 rows x 42 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codes[codes['is_golden']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"length = int(train_val_length*0.8)\\nprint(int(length))\\n\\nX_train_codes = list(codes['token_numbers'].values[:length])\\nX_train_titles = list(codes['title_token_numbers'].values[:length])\\ny_train = list(codes['is_idiomatic'].values[:length])\\n\\nX_valid_codes = list(codes['token_numbers'].values[length:train_val_length])\\nX_valid_titles = list(codes['title_token_numbers'].values[length:train_val_length])\\ny_valid = list(codes['is_idiomatic'].values[length:train_val_length])\\n\\nX_test_codes = list(codes['token_numbers'].values[train_val_length:])\\nX_test_titles = list(codes['title_token_numbers'].values[train_val_length:])\\ny_test = list(codes['is_idiomatic'].values[train_val_length:])\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"length = int(train_val_length*0.8)\n",
    "print(int(length))\n",
    "\n",
    "X_train_codes = list(codes['token_numbers'].values[:length])\n",
    "X_train_titles = list(codes['title_token_numbers'].values[:length])\n",
    "y_train = list(codes['is_idiomatic'].values[:length])\n",
    "\n",
    "X_valid_codes = list(codes['token_numbers'].values[length:train_val_length])\n",
    "X_valid_titles = list(codes['title_token_numbers'].values[length:train_val_length])\n",
    "y_valid = list(codes['is_idiomatic'].values[length:train_val_length])\n",
    "\n",
    "X_test_codes = list(codes['token_numbers'].values[train_val_length:])\n",
    "X_test_titles = list(codes['title_token_numbers'].values[train_val_length:])\n",
    "y_test = list(codes['is_idiomatic'].values[train_val_length:])\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------------------------------------------------------------------\n",
    "def create_emb_layer(weights_matrix, non_trainable=False):\n",
    "    vocab_size, embedding_dim = weights_matrix.shape\n",
    "    emb_layer = nn.Embedding(vocab_size, embedding_dim )#padding_idx=0)\n",
    "    emb_layer.weight.data.copy_(torch.from_numpy(weights_matrix).to(device))\n",
    "    \n",
    "    if non_trainable:\n",
    "        emb_layer.weight.requires_grad = False\n",
    "\n",
    "    return emb_layer,embedding_dim   \n",
    "\n",
    "    \n",
    "#---------------------------------------------------------------------------------------------------------\n",
    "class LSTM_variable_input_v2(nn.Module):\n",
    "    def __init__(self, code_weights_matrix, title_weights_matrix, hidden_dim, n_layers, \n",
    "                 bidirectional):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.code_embedding, code_embedding_dim = create_emb_layer(code_weights_matrix, True)\n",
    "        self.title_embedding, title_embedding_dim = create_emb_layer(title_weights_matrix, True)\n",
    "        \n",
    "        self.code_lstm = nn.LSTM(code_embedding_dim, \n",
    "                           hidden_dim, \n",
    "                           num_layers=n_layers, \n",
    "                           bidirectional=bidirectional, \n",
    "                           dropout=0.3)\n",
    "        self.title_lstm = nn.LSTM(title_embedding_dim, \n",
    "                           hidden_dim, \n",
    "                           num_layers=n_layers, \n",
    "                           bidirectional=bidirectional, \n",
    "                           dropout=0.3)\n",
    "        \n",
    "        self.linear = nn.Linear(hidden_dim * 2, 1)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "                \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        \n",
    "    def forward(self, codes, titles, code_lengths, title_lengths):\n",
    "        #print(\"text_lengths\")\n",
    "        #print(text_lengths)\n",
    "        #print(len(text_lengths))\n",
    "        \n",
    "        #text = [sent len, batch size]\n",
    "        \n",
    "        embedded_codes = self.dropout(self.code_embedding(codes))\n",
    "        \n",
    "        ##print(\"here1\")\n",
    "        \n",
    "        #embedded = [sent len, batch size, emb dim]\n",
    "        \n",
    "        #pack sequence\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded_codes, code_lengths, batch_first=True, enforce_sorted=False)\n",
    "        ##print(\"here2\")\n",
    "\n",
    "        packed_output, (hidden, cell) = self.code_lstm(packed_embedded)\n",
    "        ##print(\"here3\")\n",
    "\n",
    "        #unpack sequence\n",
    "        output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
    "        ##print(\"here4\")\n",
    "\n",
    "        #output = [sent len, batch size, hid dim * num directions]\n",
    "        #output over padding tokens are zero tensors\n",
    "        \n",
    "        #hidden = [num layers * num directions, batch size, hid dim]\n",
    "        #cell = [num layers * num directions, batch size, hid dim]\n",
    "        \n",
    "        #concat the final forward (hidden[-2,:,:]) and backward (hidden[-1,:,:]) hidden layers\n",
    "        #and apply dropout\n",
    "        \n",
    "        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
    "        ##print(\"here5\")\n",
    "                \n",
    "        #hidden = [batch size, hid dim * num directions]\n",
    "        code_linear_out = self.linear(hidden)\n",
    "        ##print(\"here6\")\n",
    "        \n",
    "        \n",
    "        embedded_titles = self.dropout(self.title_embedding(titles))\n",
    "        ##print(\"here7\")\n",
    "        \n",
    "        #embedded = [sent len, batch size, emb dim]\n",
    "        \n",
    "        #pack sequence\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded_titles, title_lengths, batch_first=True, enforce_sorted=False)\n",
    "        ##print(\"here8\")\n",
    "        packed_output, (hidden, cell) = self.title_lstm(packed_embedded)\n",
    "        ##print(\"here9\")\n",
    "        \n",
    "        #unpack sequence\n",
    "        output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
    "        ##print(\"here10\")\n",
    "\n",
    "        #output = [sent len, batch size, hid dim * num directions]\n",
    "        #output over padding tokens are zero tensors\n",
    "        \n",
    "        #hidden = [num layers * num directions, batch size, hid dim]\n",
    "        #cell = [num layers * num directions, batch size, hid dim]\n",
    "        \n",
    "        #concat the final forward (hidden[-2,:,:]) and backward (hidden[-1,:,:]) hidden layers\n",
    "        #and apply dropout\n",
    "        \n",
    "        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
    "        ##print(\"here11\")\n",
    "                \n",
    "        #hidden = [batch size, hid dim * num directions]\n",
    "        title_linear_out = self.linear(hidden)\n",
    "        ##print(\"here12\")\n",
    "        \n",
    "        \n",
    "        out = code_linear_out + title_linear_out\n",
    "        ##print(\"out here\")\n",
    "        \n",
    "        ##print(out)\n",
    "        \n",
    "        sigmoid_out = self.sigmoid(out)\n",
    "        #print(sigmoid_out)\n",
    "            \n",
    "        return sigmoid_out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create target Directory if don't exist\n",
    "import os \n",
    "\n",
    "def save_model(directory, model,optimizer, epoch, loss, val_f_measure):\n",
    "    dirName = \"models/\"+datetime.datetime.now().strftime(\"%x\").replace(\"/\",\"_\")\n",
    "\n",
    "    if not os.path.exists(dirName):\n",
    "        os.mkdir(dirName)\n",
    "        \n",
    "    if not os.path.exists(dirName + \"/\"+directory):\n",
    "        os.mkdir(dirName + \"/\"+directory) \n",
    "    \n",
    "    PATH = dirName + \"/\"+directory+\"/\"+datetime.datetime.now().strftime(\"%X\").replace(\":\",\"_\")\n",
    "       \n",
    "    torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': loss,\n",
    "                'val_f_measure': val_f_measure\n",
    "                }, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, val_dl, epochs=10, lr=0.0001):\n",
    "    directory = datetime.datetime.now().strftime(\"%X\").replace(\":\",\"_\")\n",
    "\n",
    "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    optimizer = optim.Adam(parameters, lr=lr)\n",
    "    loss_list = []\n",
    "    f_list = []\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        sum_loss = 0.0\n",
    "        total = 0\n",
    "        for x1,x2,y,l1,l2 in val_dl:\n",
    "            x1 = x1.long()\n",
    "            x2 = x2.long()\n",
    "            y = y.long()\n",
    "            y = y.flatten()\n",
    "            y = torch.tensor(y, dtype=torch.float) \n",
    "            x1,x2,l1,l2 = x1.to(device), x2.to(device), l1.to(device), l2.to(device)\n",
    "\n",
    "            y_pred = model(x1, x2,l1,l2)\n",
    "            y_pred = y_pred.cpu()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            loss = nn.BCELoss()(y_pred, y)\n",
    "            #loss = nn.BCEWithLogitsLoss()(y_pred, y.reshape(-1,1))\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            sum_loss += loss.item()*y.shape[0]\n",
    "            total += y.shape[0]\n",
    "        loss_list.append(sum_loss/total)\n",
    "        val_loss, val_acc, f = validation_metrics(model, val_dl)\n",
    "        if epoch % 5 == 1:\n",
    "            print(\"Epoch: \"+str(epoch))\n",
    "            print(\"train loss %.3f, val loss %.3f, and val accuracy %.3f \" % (sum_loss/total, val_loss, val_acc))\n",
    "            #print(\"Recall: \"+ str(f[\"recall\"]))\n",
    "            #print(\"Precision: \"+ str(f[\"precision\"]))\n",
    "            print(\"F-measure: \"+ str(f[\"f_measure\"]))\n",
    "            save_model(directory,model,optimizer,epoch, loss, f[\"f_measure\"])\n",
    "            f_list.append(f[\"f_measure\"])\n",
    "\n",
    "    return loss_list, f_list\n",
    "def validation_metrics (model, valid_dl):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    tp = 0\n",
    "    tn = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    total = 0\n",
    "    sum_loss = 0.0\n",
    "    sum_rmse = 0.0\n",
    "    for x1,x2,y,l1,l2 in valid_dl:\n",
    "        x1 = x1.long()\n",
    "        x2 = x2.long()\n",
    "        y = y.long()\n",
    "        y = y.flatten()\n",
    "        y = torch.tensor(y, dtype=torch.float)  \n",
    "        x1,x2,l1,l2 = x1.to(device), x2.to(device), l1.to(device), l2.to(device)\n",
    "\n",
    "        \n",
    "        y_hat = model(x1, x2,l1,l2)\n",
    "        y_hat = y_hat.cpu()\n",
    "        \n",
    "        loss = nn.BCELoss()(y_hat, y)\n",
    "        #loss = nn.BCEWithLogitsLoss()(y_hat, y.reshape(-1,1))\n",
    "        #print(y_hat)\n",
    "        pred = (y_hat>0.5).float()\n",
    "        #pred = torch.round(torch.sigmoid(y_hat))\n",
    "        #print(pred.shape)\n",
    "        #print(pred)\n",
    "        y = y.reshape(-1,1)\n",
    "        tp += ((pred == 1)&(y == 1)).float().sum() \n",
    "        tn += ((pred == 0)&(y == 0)).float().sum() \n",
    "        fp += ((pred == 1)&(y == 0)).float().sum() \n",
    "        fn += ((pred == 0)&(y == 1)).float().sum() \n",
    "        \n",
    "        total += y.shape[0]\n",
    "        sum_loss += loss.item()*y.shape[0]\n",
    "        \n",
    "    print(tp)\n",
    "    print(fp)\n",
    "    print(tn)\n",
    "    print(fn)\n",
    "    precision = tp/(tp+fp)\n",
    "    recall = tp/(tp+fn)\n",
    "    f_measure = (2 * precision * recall) / (precision + recall)\n",
    "    accuracy = (tp+tn)/(tp+tn+fp+fn)\n",
    "        \n",
    "    f = {\"precision\": precision.item(), \"recall\":recall.item(), \"f_measure\": f_measure.item(), \"accuracy\": accuracy.item()}\n",
    "    return sum_loss/total, accuracy, f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CodesDataset(Dataset):\n",
    "    def __init__(self, X_codes, X_titles, Y):\n",
    "        self.X_codes = X_codes\n",
    "        self.X_titles = X_titles\n",
    "        self.y = Y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.from_numpy(self.X_codes[idx][0].astype(np.int32)), torch.from_numpy(self.X_titles[idx][0].astype(np.int32)), self.y[idx], self.X_codes[idx][1],self.X_titles[idx][1]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14262\n"
     ]
    }
   ],
   "source": [
    "length = int(train_val_length*0.8)\n",
    "print(int(length))\n",
    "\n",
    "X_train_codes = codes[codes['is_golden']==0]['token_numbers'].values\n",
    "X_train_titles = codes[codes['is_golden']==0]['title_token_numbers'].values\n",
    "y_train = codes[codes['is_golden']==0]['is_idiomatic'].values\n",
    "\n",
    "X_test_codes = codes[codes['is_golden']==1]['token_numbers'].values\n",
    "X_test_titles = codes[codes['is_golden']==1]['title_token_numbers'].values\n",
    "y_test = codes[codes['is_golden']==1]['is_idiomatic'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = CodesDataset(X_train_codes, X_train_titles, y_train)\n",
    "#valid_ds = CodesDataset(X_valid_codes, X_valid_titles, y_valid)\n",
    "test_ds = CodesDataset(X_test_codes, X_test_titles, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1000\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "#val_dl = DataLoader(valid_ds, batch_size=batch_size)\n",
    "test_dl = DataLoader(test_ds, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")  # you can continue going on here, like cuda:1 cuda:2....etc. \n",
    "    print(\"Running on the GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Running on the CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM_variable_input_v2(\n",
       "  (code_embedding): Embedding(1818, 50)\n",
       "  (title_embedding): Embedding(818, 50)\n",
       "  (code_lstm): LSTM(50, 50, num_layers=2, dropout=0.3, bidirectional=True)\n",
       "  (title_lstm): LSTM(50, 50, num_layers=2, dropout=0.3, bidirectional=True)\n",
       "  (linear): Linear(in_features=100, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CODE_WEIGHT_METRIX = M_normalized\n",
    "TITLE_WEIGHT_METRIX = M_normalized_titles\n",
    "\n",
    "HIDDEN_DIM = 50\n",
    "N_LAYERS = 2\n",
    "BIDIRECTIONAL = True\n",
    "\n",
    "model_variable_v2_4 = LSTM_variable_input_v2(CODE_WEIGHT_METRIX, TITLE_WEIGHT_METRIX,\n",
    "            HIDDEN_DIM,\n",
    "            N_LAYERS, \n",
    "            BIDIRECTIONAL)\n",
    "model_variable_v2_4.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nimmi/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/nimmi/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:516: UserWarning: Using a target size (torch.Size([1000])) that is different to the input size (torch.Size([1000, 1])) is deprecated. Please ensure they have the same size.\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n",
      "/home/nimmi/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:516: UserWarning: Using a target size (torch.Size([598])) that is different to the input size (torch.Size([598, 1])) is deprecated. Please ensure they have the same size.\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n",
      "/home/nimmi/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(1317.)\n",
      "tensor(281.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(1317.)\n",
      "tensor(281.)\n",
      "Epoch: 1\n",
      "train loss 0.597, val loss 0.470, and val accuracy 0.824 \n",
      "F-measure: nan\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(1317.)\n",
      "tensor(281.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(1317.)\n",
      "tensor(281.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(1317.)\n",
      "tensor(281.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(1317.)\n",
      "tensor(281.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(1317.)\n",
      "tensor(281.)\n",
      "Epoch: 6\n",
      "train loss 0.466, val loss 0.466, and val accuracy 0.824 \n",
      "F-measure: nan\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(1317.)\n",
      "tensor(281.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(1317.)\n",
      "tensor(281.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(1317.)\n",
      "tensor(281.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(1317.)\n",
      "tensor(281.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(1317.)\n",
      "tensor(281.)\n",
      "Epoch: 11\n",
      "train loss 0.446, val loss 0.435, and val accuracy 0.824 \n",
      "F-measure: nan\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(1317.)\n",
      "tensor(281.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(1317.)\n",
      "tensor(281.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(1317.)\n",
      "tensor(281.)\n",
      "tensor(12.)\n",
      "tensor(2.)\n",
      "tensor(1315.)\n",
      "tensor(269.)\n",
      "tensor(72.)\n",
      "tensor(49.)\n",
      "tensor(1268.)\n",
      "tensor(209.)\n",
      "Epoch: 16\n",
      "train loss 0.385, val loss 0.361, and val accuracy 0.839 \n",
      "F-measure: 0.35820892453193665\n",
      "tensor(136.)\n",
      "tensor(118.)\n",
      "tensor(1199.)\n",
      "tensor(145.)\n",
      "tensor(119.)\n",
      "tensor(90.)\n",
      "tensor(1227.)\n",
      "tensor(162.)\n",
      "tensor(108.)\n",
      "tensor(74.)\n",
      "tensor(1243.)\n",
      "tensor(173.)\n",
      "tensor(90.)\n",
      "tensor(41.)\n",
      "tensor(1276.)\n",
      "tensor(191.)\n",
      "tensor(60.)\n",
      "tensor(21.)\n",
      "tensor(1296.)\n",
      "tensor(221.)\n",
      "Epoch: 21\n",
      "train loss 0.370, val loss 0.341, and val accuracy 0.849 \n",
      "F-measure: 0.33149170875549316\n",
      "tensor(139.)\n",
      "tensor(92.)\n",
      "tensor(1225.)\n",
      "tensor(142.)\n",
      "tensor(167.)\n",
      "tensor(110.)\n",
      "tensor(1207.)\n",
      "tensor(114.)\n",
      "tensor(135.)\n",
      "tensor(73.)\n",
      "tensor(1244.)\n",
      "tensor(146.)\n",
      "tensor(158.)\n",
      "tensor(102.)\n",
      "tensor(1215.)\n",
      "tensor(123.)\n",
      "tensor(138.)\n",
      "tensor(85.)\n",
      "tensor(1232.)\n",
      "tensor(143.)\n",
      "Epoch: 26\n",
      "train loss 0.338, val loss 0.316, and val accuracy 0.857 \n",
      "F-measure: 0.5476189851760864\n",
      "tensor(112.)\n",
      "tensor(40.)\n",
      "tensor(1277.)\n",
      "tensor(169.)\n",
      "tensor(136.)\n",
      "tensor(48.)\n",
      "tensor(1269.)\n",
      "tensor(145.)\n",
      "tensor(133.)\n",
      "tensor(55.)\n",
      "tensor(1262.)\n",
      "tensor(148.)\n",
      "tensor(119.)\n",
      "tensor(35.)\n",
      "tensor(1282.)\n",
      "tensor(162.)\n",
      "tensor(96.)\n",
      "tensor(23.)\n",
      "tensor(1294.)\n",
      "tensor(185.)\n",
      "Epoch: 31\n",
      "train loss 0.331, val loss 0.302, and val accuracy 0.870 \n",
      "F-measure: 0.47999998927116394\n",
      "tensor(137.)\n",
      "tensor(49.)\n",
      "tensor(1268.)\n",
      "tensor(144.)\n",
      "tensor(93.)\n",
      "tensor(18.)\n",
      "tensor(1299.)\n",
      "tensor(188.)\n",
      "tensor(133.)\n",
      "tensor(40.)\n",
      "tensor(1277.)\n",
      "tensor(148.)\n",
      "tensor(132.)\n",
      "tensor(36.)\n",
      "tensor(1281.)\n",
      "tensor(149.)\n",
      "tensor(119.)\n",
      "tensor(27.)\n",
      "tensor(1290.)\n",
      "tensor(162.)\n",
      "Epoch: 36\n",
      "train loss 0.313, val loss 0.288, and val accuracy 0.882 \n",
      "F-measure: 0.5573770403862\n",
      "tensor(143.)\n",
      "tensor(50.)\n",
      "tensor(1267.)\n",
      "tensor(138.)\n",
      "tensor(128.)\n",
      "tensor(35.)\n",
      "tensor(1282.)\n",
      "tensor(153.)\n",
      "tensor(132.)\n",
      "tensor(42.)\n",
      "tensor(1275.)\n",
      "tensor(149.)\n",
      "tensor(134.)\n",
      "tensor(41.)\n",
      "tensor(1276.)\n",
      "tensor(147.)\n",
      "tensor(116.)\n",
      "tensor(32.)\n",
      "tensor(1285.)\n",
      "tensor(165.)\n",
      "Epoch: 41\n",
      "train loss 0.298, val loss 0.279, and val accuracy 0.877 \n",
      "F-measure: 0.5407925248146057\n",
      "tensor(170.)\n",
      "tensor(87.)\n",
      "tensor(1230.)\n",
      "tensor(111.)\n",
      "tensor(118.)\n",
      "tensor(27.)\n",
      "tensor(1290.)\n",
      "tensor(163.)\n",
      "tensor(124.)\n",
      "tensor(33.)\n",
      "tensor(1284.)\n",
      "tensor(157.)\n",
      "tensor(131.)\n",
      "tensor(36.)\n",
      "tensor(1281.)\n",
      "tensor(150.)\n",
      "tensor(129.)\n",
      "tensor(34.)\n",
      "tensor(1283.)\n",
      "tensor(152.)\n",
      "Epoch: 46\n",
      "train loss 0.298, val loss 0.268, and val accuracy 0.884 \n",
      "F-measure: 0.5810810923576355\n",
      "tensor(148.)\n",
      "tensor(39.)\n",
      "tensor(1278.)\n",
      "tensor(133.)\n",
      "tensor(161.)\n",
      "tensor(63.)\n",
      "tensor(1254.)\n",
      "tensor(120.)\n",
      "tensor(162.)\n",
      "tensor(63.)\n",
      "tensor(1254.)\n",
      "tensor(119.)\n",
      "tensor(142.)\n",
      "tensor(41.)\n",
      "tensor(1276.)\n",
      "tensor(139.)\n",
      "tensor(152.)\n",
      "tensor(51.)\n",
      "tensor(1266.)\n",
      "tensor(129.)\n",
      "Epoch: 51\n",
      "train loss 0.277, val loss 0.258, and val accuracy 0.887 \n",
      "F-measure: 0.6280991435050964\n",
      "tensor(160.)\n",
      "tensor(56.)\n",
      "tensor(1261.)\n",
      "tensor(121.)\n",
      "tensor(140.)\n",
      "tensor(35.)\n",
      "tensor(1282.)\n",
      "tensor(141.)\n",
      "tensor(137.)\n",
      "tensor(33.)\n",
      "tensor(1284.)\n",
      "tensor(144.)\n",
      "tensor(169.)\n",
      "tensor(61.)\n",
      "tensor(1256.)\n",
      "tensor(112.)\n",
      "tensor(153.)\n",
      "tensor(52.)\n",
      "tensor(1265.)\n",
      "tensor(128.)\n",
      "Epoch: 56\n",
      "train loss 0.274, val loss 0.253, and val accuracy 0.887 \n",
      "F-measure: 0.6296296715736389\n",
      "tensor(151.)\n",
      "tensor(44.)\n",
      "tensor(1273.)\n",
      "tensor(130.)\n",
      "tensor(147.)\n",
      "tensor(39.)\n",
      "tensor(1278.)\n",
      "tensor(134.)\n",
      "tensor(161.)\n",
      "tensor(56.)\n",
      "tensor(1261.)\n",
      "tensor(120.)\n",
      "tensor(144.)\n",
      "tensor(36.)\n",
      "tensor(1281.)\n",
      "tensor(137.)\n",
      "tensor(148.)\n",
      "tensor(39.)\n",
      "tensor(1278.)\n",
      "tensor(133.)\n",
      "Epoch: 61\n",
      "train loss 0.271, val loss 0.246, and val accuracy 0.892 \n",
      "F-measure: 0.6324785947799683\n",
      "tensor(176.)\n",
      "tensor(82.)\n",
      "tensor(1235.)\n",
      "tensor(105.)\n",
      "tensor(132.)\n",
      "tensor(27.)\n",
      "tensor(1290.)\n",
      "tensor(149.)\n",
      "tensor(157.)\n",
      "tensor(47.)\n",
      "tensor(1270.)\n",
      "tensor(124.)\n",
      "tensor(160.)\n",
      "tensor(48.)\n",
      "tensor(1269.)\n",
      "tensor(121.)\n",
      "tensor(173.)\n",
      "tensor(64.)\n",
      "tensor(1253.)\n",
      "tensor(108.)\n",
      "Epoch: 66\n",
      "train loss 0.269, val loss 0.244, and val accuracy 0.892 \n",
      "F-measure: 0.6679537296295166\n",
      "tensor(173.)\n",
      "tensor(67.)\n",
      "tensor(1250.)\n",
      "tensor(108.)\n",
      "tensor(159.)\n",
      "tensor(54.)\n",
      "tensor(1263.)\n",
      "tensor(122.)\n",
      "tensor(156.)\n",
      "tensor(48.)\n",
      "tensor(1269.)\n",
      "tensor(125.)\n",
      "tensor(158.)\n",
      "tensor(44.)\n",
      "tensor(1273.)\n",
      "tensor(123.)\n",
      "tensor(172.)\n",
      "tensor(56.)\n",
      "tensor(1261.)\n",
      "tensor(109.)\n",
      "Epoch: 71\n",
      "train loss 0.260, val loss 0.237, and val accuracy 0.897 \n",
      "F-measure: 0.6758349537849426\n",
      "tensor(161.)\n",
      "tensor(45.)\n",
      "tensor(1272.)\n",
      "tensor(120.)\n",
      "tensor(196.)\n",
      "tensor(88.)\n",
      "tensor(1229.)\n",
      "tensor(85.)\n",
      "tensor(149.)\n",
      "tensor(35.)\n",
      "tensor(1282.)\n",
      "tensor(132.)\n",
      "tensor(129.)\n",
      "tensor(23.)\n",
      "tensor(1294.)\n",
      "tensor(152.)\n",
      "tensor(168.)\n",
      "tensor(60.)\n",
      "tensor(1257.)\n",
      "tensor(113.)\n",
      "Epoch: 76\n",
      "train loss 0.249, val loss 0.242, and val accuracy 0.892 \n",
      "F-measure: 0.6601178646087646\n",
      "tensor(152.)\n",
      "tensor(36.)\n",
      "tensor(1281.)\n",
      "tensor(129.)\n",
      "tensor(162.)\n",
      "tensor(37.)\n",
      "tensor(1280.)\n",
      "tensor(119.)\n",
      "tensor(176.)\n",
      "tensor(63.)\n",
      "tensor(1254.)\n",
      "tensor(105.)\n",
      "tensor(135.)\n",
      "tensor(17.)\n",
      "tensor(1300.)\n",
      "tensor(146.)\n",
      "tensor(185.)\n",
      "tensor(52.)\n",
      "tensor(1265.)\n",
      "tensor(96.)\n",
      "Epoch: 81\n",
      "train loss 0.257, val loss 0.225, and val accuracy 0.907 \n",
      "F-measure: 0.7142857313156128\n",
      "tensor(190.)\n",
      "tensor(56.)\n",
      "tensor(1261.)\n",
      "tensor(91.)\n",
      "tensor(178.)\n",
      "tensor(47.)\n",
      "tensor(1270.)\n",
      "tensor(103.)\n",
      "tensor(204.)\n",
      "tensor(75.)\n",
      "tensor(1242.)\n",
      "tensor(77.)\n",
      "tensor(175.)\n",
      "tensor(29.)\n",
      "tensor(1288.)\n",
      "tensor(106.)\n",
      "tensor(214.)\n",
      "tensor(99.)\n",
      "tensor(1218.)\n",
      "tensor(67.)\n",
      "Epoch: 86\n",
      "train loss 0.234, val loss 0.223, and val accuracy 0.896 \n",
      "F-measure: 0.7205386757850647\n",
      "tensor(170.)\n",
      "tensor(22.)\n",
      "tensor(1295.)\n",
      "tensor(111.)\n",
      "tensor(218.)\n",
      "tensor(96.)\n",
      "tensor(1221.)\n",
      "tensor(63.)\n",
      "tensor(195.)\n",
      "tensor(38.)\n",
      "tensor(1279.)\n",
      "tensor(86.)\n",
      "tensor(209.)\n",
      "tensor(53.)\n",
      "tensor(1264.)\n",
      "tensor(72.)\n",
      "tensor(195.)\n",
      "tensor(27.)\n",
      "tensor(1290.)\n",
      "tensor(86.)\n",
      "Epoch: 91\n",
      "train loss 0.214, val loss 0.186, and val accuracy 0.929 \n",
      "F-measure: 0.775347888469696\n",
      "tensor(205.)\n",
      "tensor(42.)\n",
      "tensor(1275.)\n",
      "tensor(76.)\n",
      "tensor(181.)\n",
      "tensor(16.)\n",
      "tensor(1301.)\n",
      "tensor(100.)\n",
      "tensor(226.)\n",
      "tensor(84.)\n",
      "tensor(1233.)\n",
      "tensor(55.)\n",
      "tensor(186.)\n",
      "tensor(21.)\n",
      "tensor(1296.)\n",
      "tensor(95.)\n",
      "tensor(218.)\n",
      "tensor(50.)\n",
      "tensor(1267.)\n",
      "tensor(63.)\n",
      "Epoch: 96\n",
      "train loss 0.216, val loss 0.186, and val accuracy 0.929 \n",
      "F-measure: 0.7941712141036987\n",
      "tensor(179.)\n",
      "tensor(22.)\n",
      "tensor(1295.)\n",
      "tensor(102.)\n",
      "tensor(212.)\n",
      "tensor(34.)\n",
      "tensor(1283.)\n",
      "tensor(69.)\n",
      "tensor(177.)\n",
      "tensor(9.)\n",
      "tensor(1308.)\n",
      "tensor(104.)\n",
      "tensor(227.)\n",
      "tensor(58.)\n",
      "tensor(1259.)\n",
      "tensor(54.)\n",
      "tensor(201.)\n",
      "tensor(21.)\n",
      "tensor(1296.)\n",
      "tensor(80.)\n",
      "Epoch: 101\n",
      "train loss 0.225, val loss 0.158, and val accuracy 0.937 \n",
      "F-measure: 0.7992047667503357\n",
      "tensor(200.)\n",
      "tensor(15.)\n",
      "tensor(1302.)\n",
      "tensor(81.)\n",
      "tensor(222.)\n",
      "tensor(36.)\n",
      "tensor(1281.)\n",
      "tensor(59.)\n",
      "tensor(196.)\n",
      "tensor(10.)\n",
      "tensor(1307.)\n",
      "tensor(85.)\n",
      "tensor(212.)\n",
      "tensor(16.)\n",
      "tensor(1301.)\n",
      "tensor(69.)\n",
      "tensor(221.)\n",
      "tensor(18.)\n",
      "tensor(1299.)\n",
      "tensor(60.)\n",
      "Epoch: 106\n",
      "train loss 0.185, val loss 0.140, and val accuracy 0.951 \n",
      "F-measure: 0.8499999642372131\n",
      "tensor(243.)\n",
      "tensor(39.)\n",
      "tensor(1278.)\n",
      "tensor(38.)\n",
      "tensor(194.)\n",
      "tensor(9.)\n",
      "tensor(1308.)\n",
      "tensor(87.)\n",
      "tensor(247.)\n",
      "tensor(52.)\n",
      "tensor(1265.)\n",
      "tensor(34.)\n",
      "tensor(208.)\n",
      "tensor(11.)\n",
      "tensor(1306.)\n",
      "tensor(73.)\n",
      "tensor(212.)\n",
      "tensor(13.)\n",
      "tensor(1304.)\n",
      "tensor(69.)\n",
      "Epoch: 111\n",
      "train loss 0.169, val loss 0.138, and val accuracy 0.949 \n",
      "F-measure: 0.8379446268081665\n",
      "tensor(232.)\n",
      "tensor(33.)\n",
      "tensor(1284.)\n",
      "tensor(49.)\n",
      "tensor(210.)\n",
      "tensor(10.)\n",
      "tensor(1307.)\n",
      "tensor(71.)\n",
      "tensor(236.)\n",
      "tensor(34.)\n",
      "tensor(1283.)\n",
      "tensor(45.)\n",
      "tensor(218.)\n",
      "tensor(14.)\n",
      "tensor(1303.)\n",
      "tensor(63.)\n",
      "tensor(239.)\n",
      "tensor(32.)\n",
      "tensor(1285.)\n",
      "tensor(42.)\n",
      "Epoch: 116\n",
      "train loss 0.163, val loss 0.125, and val accuracy 0.954 \n",
      "F-measure: 0.8659420013427734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(234.)\n",
      "tensor(25.)\n",
      "tensor(1292.)\n",
      "tensor(47.)\n",
      "tensor(236.)\n",
      "tensor(23.)\n",
      "tensor(1294.)\n",
      "tensor(45.)\n",
      "tensor(218.)\n",
      "tensor(13.)\n",
      "tensor(1304.)\n",
      "tensor(63.)\n",
      "tensor(240.)\n",
      "tensor(21.)\n",
      "tensor(1296.)\n",
      "tensor(41.)\n",
      "tensor(227.)\n",
      "tensor(18.)\n",
      "tensor(1299.)\n",
      "tensor(54.)\n",
      "Epoch: 121\n",
      "train loss 0.144, val loss 0.119, and val accuracy 0.955 \n",
      "F-measure: 0.8631179332733154\n",
      "tensor(246.)\n",
      "tensor(33.)\n",
      "tensor(1284.)\n",
      "tensor(35.)\n",
      "tensor(213.)\n",
      "tensor(11.)\n",
      "tensor(1306.)\n",
      "tensor(68.)\n",
      "tensor(243.)\n",
      "tensor(28.)\n",
      "tensor(1289.)\n",
      "tensor(38.)\n",
      "tensor(248.)\n",
      "tensor(21.)\n",
      "tensor(1296.)\n",
      "tensor(33.)\n",
      "tensor(239.)\n",
      "tensor(17.)\n",
      "tensor(1300.)\n",
      "tensor(42.)\n",
      "Epoch: 126\n",
      "train loss 0.144, val loss 0.099, and val accuracy 0.963 \n",
      "F-measure: 0.890130341053009\n",
      "tensor(260.)\n",
      "tensor(51.)\n",
      "tensor(1266.)\n",
      "tensor(21.)\n",
      "tensor(212.)\n",
      "tensor(9.)\n",
      "tensor(1308.)\n",
      "tensor(69.)\n",
      "tensor(248.)\n",
      "tensor(38.)\n",
      "tensor(1279.)\n",
      "tensor(33.)\n",
      "tensor(221.)\n",
      "tensor(11.)\n",
      "tensor(1306.)\n",
      "tensor(60.)\n",
      "tensor(238.)\n",
      "tensor(26.)\n",
      "tensor(1291.)\n",
      "tensor(43.)\n",
      "Epoch: 131\n",
      "train loss 0.136, val loss 0.105, and val accuracy 0.957 \n",
      "F-measure: 0.8733944296836853\n",
      "tensor(236.)\n",
      "tensor(19.)\n",
      "tensor(1298.)\n",
      "tensor(45.)\n",
      "tensor(239.)\n",
      "tensor(20.)\n",
      "tensor(1297.)\n",
      "tensor(42.)\n",
      "tensor(225.)\n",
      "tensor(13.)\n",
      "tensor(1304.)\n",
      "tensor(56.)\n",
      "tensor(253.)\n",
      "tensor(30.)\n",
      "tensor(1287.)\n",
      "tensor(28.)\n",
      "tensor(192.)\n",
      "tensor(6.)\n",
      "tensor(1311.)\n",
      "tensor(89.)\n",
      "Epoch: 136\n",
      "train loss 0.151, val loss 0.130, and val accuracy 0.941 \n",
      "F-measure: 0.8016701340675354\n",
      "tensor(255.)\n",
      "tensor(26.)\n",
      "tensor(1291.)\n",
      "tensor(26.)\n",
      "tensor(251.)\n",
      "tensor(24.)\n",
      "tensor(1293.)\n",
      "tensor(30.)\n",
      "tensor(222.)\n",
      "tensor(7.)\n",
      "tensor(1310.)\n",
      "tensor(59.)\n",
      "tensor(242.)\n",
      "tensor(12.)\n",
      "tensor(1305.)\n",
      "tensor(39.)\n",
      "tensor(247.)\n",
      "tensor(13.)\n",
      "tensor(1304.)\n",
      "tensor(34.)\n",
      "Epoch: 141\n",
      "train loss 0.124, val loss 0.081, and val accuracy 0.971 \n",
      "F-measure: 0.9131238460540771\n",
      "tensor(255.)\n",
      "tensor(20.)\n",
      "tensor(1297.)\n",
      "tensor(26.)\n",
      "tensor(251.)\n",
      "tensor(18.)\n",
      "tensor(1299.)\n",
      "tensor(30.)\n",
      "tensor(254.)\n",
      "tensor(17.)\n",
      "tensor(1300.)\n",
      "tensor(27.)\n",
      "tensor(247.)\n",
      "tensor(13.)\n",
      "tensor(1304.)\n",
      "tensor(34.)\n",
      "tensor(246.)\n",
      "tensor(8.)\n",
      "tensor(1309.)\n",
      "tensor(35.)\n",
      "Epoch: 146\n",
      "train loss 0.150, val loss 0.082, and val accuracy 0.973 \n",
      "F-measure: 0.9196261167526245\n",
      "tensor(264.)\n",
      "tensor(34.)\n",
      "tensor(1283.)\n",
      "tensor(17.)\n",
      "tensor(234.)\n",
      "tensor(9.)\n",
      "tensor(1308.)\n",
      "tensor(47.)\n",
      "tensor(256.)\n",
      "tensor(24.)\n",
      "tensor(1293.)\n",
      "tensor(25.)\n",
      "tensor(245.)\n",
      "tensor(16.)\n",
      "tensor(1301.)\n",
      "tensor(36.)\n",
      "tensor(230.)\n",
      "tensor(10.)\n",
      "tensor(1307.)\n",
      "tensor(51.)\n",
      "Epoch: 151\n",
      "train loss 0.116, val loss 0.097, and val accuracy 0.962 \n",
      "F-measure: 0.8829174637794495\n",
      "tensor(256.)\n",
      "tensor(16.)\n",
      "tensor(1301.)\n",
      "tensor(25.)\n",
      "tensor(245.)\n",
      "tensor(10.)\n",
      "tensor(1307.)\n",
      "tensor(36.)\n",
      "tensor(256.)\n",
      "tensor(16.)\n",
      "tensor(1301.)\n",
      "tensor(25.)\n",
      "tensor(248.)\n",
      "tensor(12.)\n",
      "tensor(1305.)\n",
      "tensor(33.)\n",
      "tensor(252.)\n",
      "tensor(18.)\n",
      "tensor(1299.)\n",
      "tensor(29.)\n",
      "Epoch: 156\n",
      "train loss 0.125, val loss 0.083, and val accuracy 0.971 \n",
      "F-measure: 0.9147005081176758\n",
      "tensor(259.)\n",
      "tensor(19.)\n",
      "tensor(1298.)\n",
      "tensor(22.)\n",
      "tensor(255.)\n",
      "tensor(11.)\n",
      "tensor(1306.)\n",
      "tensor(26.)\n",
      "tensor(250.)\n",
      "tensor(11.)\n",
      "tensor(1306.)\n",
      "tensor(31.)\n",
      "tensor(248.)\n",
      "tensor(11.)\n",
      "tensor(1306.)\n",
      "tensor(33.)\n",
      "tensor(240.)\n",
      "tensor(4.)\n",
      "tensor(1313.)\n",
      "tensor(41.)\n",
      "Epoch: 161\n",
      "train loss 0.098, val loss 0.075, and val accuracy 0.972 \n",
      "F-measure: 0.9142857193946838\n",
      "tensor(259.)\n",
      "tensor(11.)\n",
      "tensor(1306.)\n",
      "tensor(22.)\n",
      "tensor(257.)\n",
      "tensor(9.)\n",
      "tensor(1308.)\n",
      "tensor(24.)\n",
      "tensor(262.)\n",
      "tensor(10.)\n",
      "tensor(1307.)\n",
      "tensor(19.)\n",
      "tensor(258.)\n",
      "tensor(12.)\n",
      "tensor(1305.)\n",
      "tensor(23.)\n",
      "tensor(247.)\n",
      "tensor(7.)\n",
      "tensor(1310.)\n",
      "tensor(34.)\n",
      "Epoch: 166\n",
      "train loss 0.098, val loss 0.064, and val accuracy 0.974 \n",
      "F-measure: 0.923364520072937\n",
      "tensor(261.)\n",
      "tensor(13.)\n",
      "tensor(1304.)\n",
      "tensor(20.)\n",
      "tensor(248.)\n",
      "tensor(9.)\n",
      "tensor(1308.)\n",
      "tensor(33.)\n",
      "tensor(266.)\n",
      "tensor(21.)\n",
      "tensor(1296.)\n",
      "tensor(15.)\n",
      "tensor(254.)\n",
      "tensor(12.)\n",
      "tensor(1305.)\n",
      "tensor(27.)\n",
      "tensor(267.)\n",
      "tensor(20.)\n",
      "tensor(1297.)\n",
      "tensor(14.)\n",
      "Epoch: 171\n",
      "train loss 0.090, val loss 0.066, and val accuracy 0.979 \n",
      "F-measure: 0.9401408433914185\n",
      "tensor(239.)\n",
      "tensor(4.)\n",
      "tensor(1313.)\n",
      "tensor(42.)\n",
      "tensor(270.)\n",
      "tensor(35.)\n",
      "tensor(1282.)\n",
      "tensor(11.)\n",
      "tensor(237.)\n",
      "tensor(3.)\n",
      "tensor(1314.)\n",
      "tensor(44.)\n",
      "tensor(265.)\n",
      "tensor(13.)\n",
      "tensor(1304.)\n",
      "tensor(16.)\n",
      "tensor(264.)\n",
      "tensor(14.)\n",
      "tensor(1303.)\n",
      "tensor(17.)\n",
      "Epoch: 176\n",
      "train loss 0.121, val loss 0.063, and val accuracy 0.981 \n",
      "F-measure: 0.9445438385009766\n",
      "tensor(254.)\n",
      "tensor(6.)\n",
      "tensor(1311.)\n",
      "tensor(27.)\n",
      "tensor(265.)\n",
      "tensor(13.)\n",
      "tensor(1304.)\n",
      "tensor(16.)\n",
      "tensor(261.)\n",
      "tensor(11.)\n",
      "tensor(1306.)\n",
      "tensor(20.)\n",
      "tensor(240.)\n",
      "tensor(5.)\n",
      "tensor(1312.)\n",
      "tensor(41.)\n",
      "tensor(271.)\n",
      "tensor(79.)\n",
      "tensor(1238.)\n",
      "tensor(10.)\n",
      "Epoch: 181\n",
      "train loss 0.147, val loss 0.121, and val accuracy 0.944 \n",
      "F-measure: 0.858954131603241\n",
      "tensor(244.)\n",
      "tensor(5.)\n",
      "tensor(1312.)\n",
      "tensor(37.)\n",
      "tensor(218.)\n",
      "tensor(2.)\n",
      "tensor(1315.)\n",
      "tensor(63.)\n",
      "tensor(258.)\n",
      "tensor(16.)\n",
      "tensor(1301.)\n",
      "tensor(23.)\n",
      "tensor(259.)\n",
      "tensor(11.)\n",
      "tensor(1306.)\n",
      "tensor(22.)\n",
      "tensor(239.)\n",
      "tensor(6.)\n",
      "tensor(1311.)\n",
      "tensor(42.)\n",
      "Epoch: 186\n",
      "train loss 0.103, val loss 0.079, and val accuracy 0.970 \n",
      "F-measure: 0.9087452292442322\n",
      "tensor(268.)\n",
      "tensor(24.)\n",
      "tensor(1293.)\n",
      "tensor(13.)\n",
      "tensor(266.)\n",
      "tensor(19.)\n",
      "tensor(1298.)\n",
      "tensor(15.)\n",
      "tensor(242.)\n",
      "tensor(6.)\n",
      "tensor(1311.)\n",
      "tensor(39.)\n",
      "tensor(262.)\n",
      "tensor(9.)\n",
      "tensor(1308.)\n",
      "tensor(19.)\n",
      "tensor(265.)\n",
      "tensor(23.)\n",
      "tensor(1294.)\n",
      "tensor(16.)\n",
      "Epoch: 191\n",
      "train loss 0.089, val loss 0.071, and val accuracy 0.976 \n",
      "F-measure: 0.9314586520195007\n",
      "tensor(254.)\n",
      "tensor(12.)\n",
      "tensor(1305.)\n",
      "tensor(27.)\n",
      "tensor(237.)\n",
      "tensor(5.)\n",
      "tensor(1312.)\n",
      "tensor(44.)\n",
      "tensor(265.)\n",
      "tensor(11.)\n",
      "tensor(1306.)\n",
      "tensor(16.)\n",
      "tensor(269.)\n",
      "tensor(17.)\n",
      "tensor(1300.)\n",
      "tensor(12.)\n",
      "tensor(265.)\n",
      "tensor(9.)\n",
      "tensor(1308.)\n",
      "tensor(16.)\n",
      "Epoch: 196\n",
      "train loss 0.095, val loss 0.051, and val accuracy 0.984 \n",
      "F-measure: 0.954954981803894\n",
      "tensor(256.)\n",
      "tensor(7.)\n",
      "tensor(1310.)\n",
      "tensor(25.)\n",
      "tensor(266.)\n",
      "tensor(10.)\n",
      "tensor(1307.)\n",
      "tensor(15.)\n",
      "tensor(269.)\n",
      "tensor(12.)\n",
      "tensor(1305.)\n",
      "tensor(12.)\n",
      "tensor(269.)\n",
      "tensor(17.)\n",
      "tensor(1300.)\n",
      "tensor(12.)\n",
      "tensor(267.)\n",
      "tensor(12.)\n",
      "tensor(1305.)\n",
      "tensor(14.)\n",
      "Epoch: 201\n",
      "train loss 0.075, val loss 0.044, and val accuracy 0.984 \n",
      "F-measure: 0.9535713791847229\n",
      "tensor(264.)\n",
      "tensor(6.)\n",
      "tensor(1311.)\n",
      "tensor(17.)\n",
      "tensor(267.)\n",
      "tensor(16.)\n",
      "tensor(1301.)\n",
      "tensor(14.)\n",
      "tensor(262.)\n",
      "tensor(8.)\n",
      "tensor(1309.)\n",
      "tensor(19.)\n",
      "tensor(264.)\n",
      "tensor(5.)\n",
      "tensor(1312.)\n",
      "tensor(17.)\n",
      "tensor(266.)\n",
      "tensor(5.)\n",
      "tensor(1312.)\n",
      "tensor(15.)\n",
      "Epoch: 206\n",
      "train loss 0.082, val loss 0.038, and val accuracy 0.987 \n",
      "F-measure: 0.9637681245803833\n",
      "tensor(270.)\n",
      "tensor(12.)\n",
      "tensor(1305.)\n",
      "tensor(11.)\n",
      "tensor(267.)\n",
      "tensor(6.)\n",
      "tensor(1311.)\n",
      "tensor(14.)\n",
      "tensor(261.)\n",
      "tensor(3.)\n",
      "tensor(1314.)\n",
      "tensor(20.)\n",
      "tensor(271.)\n",
      "tensor(8.)\n",
      "tensor(1309.)\n",
      "tensor(10.)\n",
      "tensor(273.)\n",
      "tensor(9.)\n",
      "tensor(1308.)\n",
      "tensor(8.)\n",
      "Epoch: 211\n",
      "train loss 0.076, val loss 0.035, and val accuracy 0.989 \n",
      "F-measure: 0.9698046445846558\n",
      "tensor(266.)\n",
      "tensor(5.)\n",
      "tensor(1312.)\n",
      "tensor(15.)\n",
      "tensor(270.)\n",
      "tensor(5.)\n",
      "tensor(1312.)\n",
      "tensor(11.)\n",
      "tensor(274.)\n",
      "tensor(14.)\n",
      "tensor(1303.)\n",
      "tensor(7.)\n",
      "tensor(263.)\n",
      "tensor(3.)\n",
      "tensor(1314.)\n",
      "tensor(18.)\n",
      "tensor(265.)\n",
      "tensor(3.)\n",
      "tensor(1314.)\n",
      "tensor(16.)\n",
      "Epoch: 216\n",
      "train loss 0.072, val loss 0.040, and val accuracy 0.988 \n",
      "F-measure: 0.9653916954994202\n",
      "tensor(271.)\n",
      "tensor(15.)\n",
      "tensor(1302.)\n",
      "tensor(10.)\n",
      "tensor(267.)\n",
      "tensor(3.)\n",
      "tensor(1314.)\n",
      "tensor(14.)\n",
      "tensor(269.)\n",
      "tensor(4.)\n",
      "tensor(1313.)\n",
      "tensor(12.)\n",
      "tensor(273.)\n",
      "tensor(10.)\n",
      "tensor(1307.)\n",
      "tensor(8.)\n",
      "tensor(271.)\n",
      "tensor(4.)\n",
      "tensor(1313.)\n",
      "tensor(10.)\n",
      "Epoch: 221\n",
      "train loss 0.072, val loss 0.035, and val accuracy 0.991 \n",
      "F-measure: 0.9748201370239258\n",
      "tensor(271.)\n",
      "tensor(3.)\n",
      "tensor(1314.)\n",
      "tensor(10.)\n",
      "tensor(261.)\n",
      "tensor(2.)\n",
      "tensor(1315.)\n",
      "tensor(20.)\n",
      "tensor(269.)\n",
      "tensor(5.)\n",
      "tensor(1312.)\n",
      "tensor(12.)\n",
      "tensor(274.)\n",
      "tensor(11.)\n",
      "tensor(1306.)\n",
      "tensor(7.)\n",
      "tensor(267.)\n",
      "tensor(4.)\n",
      "tensor(1313.)\n",
      "tensor(14.)\n",
      "Epoch: 226\n",
      "train loss 0.062, val loss 0.037, and val accuracy 0.989 \n",
      "F-measure: 0.967391312122345\n",
      "tensor(273.)\n",
      "tensor(3.)\n",
      "tensor(1314.)\n",
      "tensor(8.)\n",
      "tensor(275.)\n",
      "tensor(10.)\n",
      "tensor(1307.)\n",
      "tensor(6.)\n",
      "tensor(262.)\n",
      "tensor(4.)\n",
      "tensor(1313.)\n",
      "tensor(19.)\n",
      "tensor(266.)\n",
      "tensor(6.)\n",
      "tensor(1311.)\n",
      "tensor(15.)\n",
      "tensor(274.)\n",
      "tensor(12.)\n",
      "tensor(1305.)\n",
      "tensor(7.)\n",
      "Epoch: 231\n",
      "train loss 0.092, val loss 0.034, and val accuracy 0.988 \n",
      "F-measure: 0.9664902687072754\n",
      "tensor(274.)\n",
      "tensor(8.)\n",
      "tensor(1309.)\n",
      "tensor(7.)\n",
      "tensor(277.)\n",
      "tensor(12.)\n",
      "tensor(1305.)\n",
      "tensor(4.)\n",
      "tensor(274.)\n",
      "tensor(15.)\n",
      "tensor(1302.)\n",
      "tensor(7.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(264.)\n",
      "tensor(13.)\n",
      "tensor(1304.)\n",
      "tensor(17.)\n",
      "tensor(262.)\n",
      "tensor(1.)\n",
      "tensor(1316.)\n",
      "tensor(19.)\n",
      "Epoch: 236\n",
      "train loss 0.075, val loss 0.032, and val accuracy 0.987 \n",
      "F-measure: 0.9632352590560913\n",
      "tensor(268.)\n",
      "tensor(2.)\n",
      "tensor(1315.)\n",
      "tensor(13.)\n",
      "tensor(273.)\n",
      "tensor(4.)\n",
      "tensor(1313.)\n",
      "tensor(8.)\n",
      "tensor(272.)\n",
      "tensor(4.)\n",
      "tensor(1313.)\n",
      "tensor(9.)\n",
      "tensor(272.)\n",
      "tensor(4.)\n",
      "tensor(1313.)\n",
      "tensor(9.)\n",
      "tensor(271.)\n",
      "tensor(4.)\n",
      "tensor(1313.)\n",
      "tensor(10.)\n",
      "Epoch: 241\n",
      "train loss 0.054, val loss 0.026, and val accuracy 0.991 \n",
      "F-measure: 0.9748201370239258\n",
      "tensor(271.)\n",
      "tensor(3.)\n",
      "tensor(1314.)\n",
      "tensor(10.)\n",
      "tensor(274.)\n",
      "tensor(6.)\n",
      "tensor(1311.)\n",
      "tensor(7.)\n",
      "tensor(276.)\n",
      "tensor(6.)\n",
      "tensor(1311.)\n",
      "tensor(5.)\n",
      "tensor(269.)\n",
      "tensor(4.)\n",
      "tensor(1313.)\n",
      "tensor(12.)\n",
      "tensor(267.)\n",
      "tensor(4.)\n",
      "tensor(1313.)\n",
      "tensor(14.)\n",
      "Epoch: 246\n",
      "train loss 0.061, val loss 0.026, and val accuracy 0.989 \n",
      "F-measure: 0.967391312122345\n",
      "tensor(275.)\n",
      "tensor(10.)\n",
      "tensor(1307.)\n",
      "tensor(6.)\n",
      "tensor(271.)\n",
      "tensor(4.)\n",
      "tensor(1313.)\n",
      "tensor(10.)\n",
      "tensor(266.)\n",
      "tensor(3.)\n",
      "tensor(1314.)\n",
      "tensor(15.)\n",
      "tensor(273.)\n",
      "tensor(3.)\n",
      "tensor(1314.)\n",
      "tensor(8.)\n",
      "tensor(274.)\n",
      "tensor(5.)\n",
      "tensor(1312.)\n",
      "tensor(7.)\n",
      "Epoch: 251\n",
      "train loss 0.049, val loss 0.025, and val accuracy 0.992 \n",
      "F-measure: 0.9785714149475098\n",
      "tensor(273.)\n",
      "tensor(3.)\n",
      "tensor(1314.)\n",
      "tensor(8.)\n",
      "tensor(274.)\n",
      "tensor(5.)\n",
      "tensor(1312.)\n",
      "tensor(7.)\n",
      "tensor(273.)\n",
      "tensor(4.)\n",
      "tensor(1313.)\n",
      "tensor(8.)\n",
      "tensor(271.)\n",
      "tensor(4.)\n",
      "tensor(1313.)\n",
      "tensor(10.)\n",
      "tensor(276.)\n",
      "tensor(4.)\n",
      "tensor(1313.)\n",
      "tensor(5.)\n",
      "Epoch: 256\n",
      "train loss 0.069, val loss 0.019, and val accuracy 0.994 \n",
      "F-measure: 0.9839572310447693\n",
      "tensor(274.)\n",
      "tensor(4.)\n",
      "tensor(1313.)\n",
      "tensor(7.)\n",
      "tensor(275.)\n",
      "tensor(6.)\n",
      "tensor(1311.)\n",
      "tensor(6.)\n",
      "tensor(273.)\n",
      "tensor(5.)\n",
      "tensor(1312.)\n",
      "tensor(8.)\n",
      "tensor(274.)\n",
      "tensor(6.)\n",
      "tensor(1311.)\n",
      "tensor(7.)\n",
      "tensor(275.)\n",
      "tensor(8.)\n",
      "tensor(1309.)\n",
      "tensor(6.)\n",
      "Epoch: 261\n",
      "train loss 0.054, val loss 0.023, and val accuracy 0.991 \n",
      "F-measure: 0.9751773476600647\n",
      "tensor(278.)\n",
      "tensor(8.)\n",
      "tensor(1309.)\n",
      "tensor(3.)\n",
      "tensor(273.)\n",
      "tensor(4.)\n",
      "tensor(1313.)\n",
      "tensor(8.)\n",
      "tensor(276.)\n",
      "tensor(4.)\n",
      "tensor(1313.)\n",
      "tensor(5.)\n",
      "tensor(276.)\n",
      "tensor(4.)\n",
      "tensor(1313.)\n",
      "tensor(5.)\n",
      "tensor(275.)\n",
      "tensor(3.)\n",
      "tensor(1314.)\n",
      "tensor(6.)\n",
      "Epoch: 266\n",
      "train loss 0.052, val loss 0.021, and val accuracy 0.994 \n",
      "F-measure: 0.9838998317718506\n",
      "tensor(273.)\n",
      "tensor(2.)\n",
      "tensor(1315.)\n",
      "tensor(8.)\n",
      "tensor(277.)\n",
      "tensor(5.)\n",
      "tensor(1312.)\n",
      "tensor(4.)\n",
      "tensor(276.)\n",
      "tensor(3.)\n",
      "tensor(1314.)\n",
      "tensor(5.)\n",
      "tensor(270.)\n",
      "tensor(3.)\n",
      "tensor(1314.)\n",
      "tensor(11.)\n",
      "tensor(276.)\n",
      "tensor(4.)\n",
      "tensor(1313.)\n",
      "tensor(5.)\n",
      "Epoch: 271\n",
      "train loss 0.046, val loss 0.020, and val accuracy 0.994 \n",
      "F-measure: 0.9839572310447693\n",
      "tensor(274.)\n",
      "tensor(6.)\n",
      "tensor(1311.)\n",
      "tensor(7.)\n",
      "tensor(272.)\n",
      "tensor(4.)\n",
      "tensor(1313.)\n",
      "tensor(9.)\n",
      "tensor(276.)\n",
      "tensor(3.)\n",
      "tensor(1314.)\n",
      "tensor(5.)\n",
      "tensor(277.)\n",
      "tensor(2.)\n",
      "tensor(1315.)\n",
      "tensor(4.)\n",
      "tensor(278.)\n",
      "tensor(3.)\n",
      "tensor(1314.)\n",
      "tensor(3.)\n",
      "Epoch: 276\n",
      "train loss 0.050, val loss 0.015, and val accuracy 0.996 \n",
      "F-measure: 0.9893238544464111\n",
      "tensor(277.)\n",
      "tensor(4.)\n",
      "tensor(1313.)\n",
      "tensor(4.)\n",
      "tensor(272.)\n",
      "tensor(2.)\n",
      "tensor(1315.)\n",
      "tensor(9.)\n",
      "tensor(278.)\n",
      "tensor(10.)\n",
      "tensor(1307.)\n",
      "tensor(3.)\n",
      "tensor(278.)\n",
      "tensor(8.)\n",
      "tensor(1309.)\n",
      "tensor(3.)\n",
      "tensor(269.)\n",
      "tensor(3.)\n",
      "tensor(1314.)\n",
      "tensor(12.)\n",
      "Epoch: 281\n",
      "train loss 0.056, val loss 0.033, and val accuracy 0.991 \n",
      "F-measure: 0.97287517786026\n",
      "tensor(274.)\n",
      "tensor(6.)\n",
      "tensor(1311.)\n",
      "tensor(7.)\n",
      "tensor(279.)\n",
      "tensor(12.)\n",
      "tensor(1305.)\n",
      "tensor(2.)\n",
      "tensor(273.)\n",
      "tensor(4.)\n",
      "tensor(1313.)\n",
      "tensor(8.)\n",
      "tensor(275.)\n",
      "tensor(3.)\n",
      "tensor(1314.)\n",
      "tensor(6.)\n",
      "tensor(276.)\n",
      "tensor(5.)\n",
      "tensor(1312.)\n",
      "tensor(5.)\n",
      "Epoch: 286\n",
      "train loss 0.054, val loss 0.019, and val accuracy 0.994 \n",
      "F-measure: 0.982206404209137\n",
      "tensor(276.)\n",
      "tensor(5.)\n",
      "tensor(1312.)\n",
      "tensor(5.)\n",
      "tensor(279.)\n",
      "tensor(6.)\n",
      "tensor(1311.)\n",
      "tensor(2.)\n",
      "tensor(278.)\n",
      "tensor(7.)\n",
      "tensor(1310.)\n",
      "tensor(3.)\n",
      "tensor(278.)\n",
      "tensor(5.)\n",
      "tensor(1312.)\n",
      "tensor(3.)\n",
      "tensor(278.)\n",
      "tensor(7.)\n",
      "tensor(1310.)\n",
      "tensor(3.)\n",
      "Epoch: 291\n",
      "train loss 0.047, val loss 0.021, and val accuracy 0.994 \n",
      "F-measure: 0.9823321104049683\n",
      "tensor(276.)\n",
      "tensor(5.)\n",
      "tensor(1312.)\n",
      "tensor(5.)\n",
      "tensor(273.)\n",
      "tensor(3.)\n",
      "tensor(1314.)\n",
      "tensor(8.)\n",
      "tensor(277.)\n",
      "tensor(2.)\n",
      "tensor(1315.)\n",
      "tensor(4.)\n",
      "tensor(276.)\n",
      "tensor(2.)\n",
      "tensor(1315.)\n",
      "tensor(5.)\n",
      "tensor(277.)\n",
      "tensor(2.)\n",
      "tensor(1315.)\n",
      "tensor(4.)\n",
      "Epoch: 296\n",
      "train loss 0.056, val loss 0.019, and val accuracy 0.996 \n",
      "F-measure: 0.9892856478691101\n",
      "tensor(277.)\n",
      "tensor(2.)\n",
      "tensor(1315.)\n",
      "tensor(4.)\n",
      "tensor(278.)\n",
      "tensor(3.)\n",
      "tensor(1314.)\n",
      "tensor(3.)\n",
      "tensor(275.)\n",
      "tensor(3.)\n",
      "tensor(1314.)\n",
      "tensor(6.)\n",
      "tensor(277.)\n",
      "tensor(3.)\n",
      "tensor(1314.)\n",
      "tensor(4.)\n",
      "tensor(279.)\n",
      "tensor(3.)\n",
      "tensor(1314.)\n",
      "tensor(2.)\n",
      "Epoch: 301\n",
      "train loss 0.048, val loss 0.013, and val accuracy 0.997 \n",
      "F-measure: 0.9911189675331116\n",
      "tensor(278.)\n",
      "tensor(5.)\n",
      "tensor(1312.)\n",
      "tensor(3.)\n",
      "tensor(279.)\n",
      "tensor(5.)\n",
      "tensor(1312.)\n",
      "tensor(2.)\n",
      "tensor(279.)\n",
      "tensor(5.)\n",
      "tensor(1312.)\n",
      "tensor(2.)\n",
      "tensor(279.)\n",
      "tensor(3.)\n",
      "tensor(1314.)\n",
      "tensor(2.)\n",
      "tensor(279.)\n",
      "tensor(3.)\n",
      "tensor(1314.)\n",
      "tensor(2.)\n",
      "Epoch: 306\n",
      "train loss 0.054, val loss 0.012, and val accuracy 0.997 \n",
      "F-measure: 0.9911189675331116\n",
      "tensor(279.)\n",
      "tensor(6.)\n",
      "tensor(1311.)\n",
      "tensor(2.)\n",
      "tensor(279.)\n",
      "tensor(5.)\n",
      "tensor(1312.)\n",
      "tensor(2.)\n",
      "tensor(278.)\n",
      "tensor(3.)\n",
      "tensor(1314.)\n",
      "tensor(3.)\n",
      "tensor(279.)\n",
      "tensor(7.)\n",
      "tensor(1310.)\n",
      "tensor(2.)\n",
      "tensor(278.)\n",
      "tensor(6.)\n",
      "tensor(1311.)\n",
      "tensor(3.)\n",
      "Epoch: 311\n",
      "train loss 0.065, val loss 0.016, and val accuracy 0.994 \n",
      "F-measure: 0.9840707778930664\n",
      "tensor(274.)\n",
      "tensor(3.)\n",
      "tensor(1314.)\n",
      "tensor(7.)\n",
      "tensor(277.)\n",
      "tensor(5.)\n",
      "tensor(1312.)\n",
      "tensor(4.)\n",
      "tensor(279.)\n",
      "tensor(11.)\n",
      "tensor(1306.)\n",
      "tensor(2.)\n",
      "tensor(279.)\n",
      "tensor(4.)\n",
      "tensor(1313.)\n",
      "tensor(2.)\n",
      "tensor(275.)\n",
      "tensor(3.)\n",
      "tensor(1314.)\n",
      "tensor(6.)\n",
      "Epoch: 316\n",
      "train loss 0.050, val loss 0.014, and val accuracy 0.994 \n",
      "F-measure: 0.9838998317718506\n",
      "tensor(277.)\n",
      "tensor(4.)\n",
      "tensor(1313.)\n",
      "tensor(4.)\n",
      "tensor(278.)\n",
      "tensor(4.)\n",
      "tensor(1313.)\n",
      "tensor(3.)\n",
      "tensor(279.)\n",
      "tensor(5.)\n",
      "tensor(1312.)\n",
      "tensor(2.)\n",
      "tensor(279.)\n",
      "tensor(3.)\n",
      "tensor(1314.)\n",
      "tensor(2.)\n",
      "tensor(276.)\n",
      "tensor(4.)\n",
      "tensor(1313.)\n",
      "tensor(5.)\n",
      "Epoch: 321\n",
      "train loss 0.054, val loss 0.018, and val accuracy 0.994 \n",
      "F-measure: 0.9839572310447693\n",
      "tensor(278.)\n",
      "tensor(5.)\n",
      "tensor(1312.)\n",
      "tensor(3.)\n",
      "tensor(278.)\n",
      "tensor(8.)\n",
      "tensor(1309.)\n",
      "tensor(3.)\n",
      "tensor(278.)\n",
      "tensor(4.)\n",
      "tensor(1313.)\n",
      "tensor(3.)\n",
      "tensor(276.)\n",
      "tensor(4.)\n",
      "tensor(1313.)\n",
      "tensor(5.)\n",
      "tensor(278.)\n",
      "tensor(6.)\n",
      "tensor(1311.)\n",
      "tensor(3.)\n",
      "Epoch: 326\n",
      "train loss 0.053, val loss 0.014, and val accuracy 0.994 \n",
      "F-measure: 0.9840707778930664\n",
      "tensor(280.)\n",
      "tensor(9.)\n",
      "tensor(1308.)\n",
      "tensor(1.)\n",
      "tensor(276.)\n",
      "tensor(2.)\n",
      "tensor(1315.)\n",
      "tensor(5.)\n",
      "tensor(279.)\n",
      "tensor(7.)\n",
      "tensor(1310.)\n",
      "tensor(2.)\n",
      "tensor(277.)\n",
      "tensor(2.)\n",
      "tensor(1315.)\n",
      "tensor(4.)\n",
      "tensor(269.)\n",
      "tensor(1.)\n",
      "tensor(1316.)\n",
      "tensor(12.)\n",
      "Epoch: 331\n",
      "train loss 0.052, val loss 0.021, and val accuracy 0.992 \n",
      "F-measure: 0.9764065742492676\n",
      "tensor(273.)\n",
      "tensor(2.)\n",
      "tensor(1315.)\n",
      "tensor(8.)\n",
      "tensor(279.)\n",
      "tensor(3.)\n",
      "tensor(1314.)\n",
      "tensor(2.)\n",
      "tensor(279.)\n",
      "tensor(3.)\n",
      "tensor(1314.)\n",
      "tensor(2.)\n",
      "tensor(279.)\n",
      "tensor(3.)\n",
      "tensor(1314.)\n",
      "tensor(2.)\n",
      "tensor(274.)\n",
      "tensor(3.)\n",
      "tensor(1314.)\n",
      "tensor(7.)\n",
      "Epoch: 336\n",
      "train loss 0.048, val loss 0.019, and val accuracy 0.994 \n",
      "F-measure: 0.9820787906646729\n",
      "tensor(280.)\n",
      "tensor(6.)\n",
      "tensor(1311.)\n",
      "tensor(1.)\n",
      "tensor(276.)\n",
      "tensor(3.)\n",
      "tensor(1314.)\n",
      "tensor(5.)\n",
      "tensor(275.)\n",
      "tensor(3.)\n",
      "tensor(1314.)\n",
      "tensor(6.)\n",
      "tensor(276.)\n",
      "tensor(4.)\n",
      "tensor(1313.)\n",
      "tensor(5.)\n",
      "tensor(276.)\n",
      "tensor(7.)\n",
      "tensor(1310.)\n",
      "tensor(5.)\n",
      "Epoch: 341\n",
      "train loss 0.055, val loss 0.019, and val accuracy 0.992 \n",
      "F-measure: 0.978723406791687\n",
      "tensor(272.)\n",
      "tensor(2.)\n",
      "tensor(1315.)\n",
      "tensor(9.)\n",
      "tensor(271.)\n",
      "tensor(2.)\n",
      "tensor(1315.)\n",
      "tensor(10.)\n",
      "tensor(275.)\n",
      "tensor(3.)\n",
      "tensor(1314.)\n",
      "tensor(6.)\n",
      "tensor(278.)\n",
      "tensor(4.)\n",
      "tensor(1313.)\n",
      "tensor(3.)\n",
      "tensor(278.)\n",
      "tensor(2.)\n",
      "tensor(1315.)\n",
      "tensor(3.)\n",
      "Epoch: 346\n",
      "train loss 0.052, val loss 0.015, and val accuracy 0.997 \n",
      "F-measure: 0.9910873174667358\n",
      "tensor(276.)\n",
      "tensor(2.)\n",
      "tensor(1315.)\n",
      "tensor(5.)\n",
      "tensor(278.)\n",
      "tensor(3.)\n",
      "tensor(1314.)\n",
      "tensor(3.)\n",
      "tensor(279.)\n",
      "tensor(11.)\n",
      "tensor(1306.)\n",
      "tensor(2.)\n",
      "tensor(278.)\n",
      "tensor(9.)\n",
      "tensor(1308.)\n",
      "tensor(3.)\n",
      "tensor(278.)\n",
      "tensor(2.)\n",
      "tensor(1315.)\n",
      "tensor(3.)\n",
      "Epoch: 351\n",
      "train loss 0.047, val loss 0.013, and val accuracy 0.997 \n",
      "F-measure: 0.9910873174667358\n",
      "tensor(277.)\n",
      "tensor(2.)\n",
      "tensor(1315.)\n",
      "tensor(4.)\n",
      "tensor(278.)\n",
      "tensor(5.)\n",
      "tensor(1312.)\n",
      "tensor(3.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(279.)\n",
      "tensor(8.)\n",
      "tensor(1309.)\n",
      "tensor(2.)\n",
      "tensor(275.)\n",
      "tensor(6.)\n",
      "tensor(1311.)\n",
      "tensor(6.)\n",
      "tensor(273.)\n",
      "tensor(3.)\n",
      "tensor(1314.)\n",
      "tensor(8.)\n",
      "Epoch: 356\n",
      "train loss 0.044, val loss 0.018, and val accuracy 0.993 \n",
      "F-measure: 0.9802513718605042\n",
      "tensor(278.)\n",
      "tensor(4.)\n",
      "tensor(1313.)\n",
      "tensor(3.)\n",
      "tensor(278.)\n",
      "tensor(4.)\n",
      "tensor(1313.)\n",
      "tensor(3.)\n",
      "tensor(278.)\n",
      "tensor(3.)\n",
      "tensor(1314.)\n",
      "tensor(3.)\n",
      "tensor(277.)\n",
      "tensor(4.)\n",
      "tensor(1313.)\n",
      "tensor(4.)\n",
      "tensor(278.)\n",
      "tensor(3.)\n",
      "tensor(1314.)\n",
      "tensor(3.)\n",
      "Epoch: 361\n",
      "train loss 0.055, val loss 0.014, and val accuracy 0.996 \n",
      "F-measure: 0.9893238544464111\n",
      "tensor(278.)\n",
      "tensor(3.)\n",
      "tensor(1314.)\n",
      "tensor(3.)\n",
      "tensor(277.)\n",
      "tensor(3.)\n",
      "tensor(1314.)\n",
      "tensor(4.)\n",
      "tensor(278.)\n",
      "tensor(3.)\n",
      "tensor(1314.)\n",
      "tensor(3.)\n",
      "tensor(278.)\n",
      "tensor(4.)\n",
      "tensor(1313.)\n",
      "tensor(3.)\n",
      "tensor(279.)\n",
      "tensor(4.)\n",
      "tensor(1313.)\n",
      "tensor(2.)\n",
      "Epoch: 366\n",
      "train loss 0.041, val loss 0.014, and val accuracy 0.996 \n",
      "F-measure: 0.9893616437911987\n",
      "tensor(276.)\n",
      "tensor(1.)\n",
      "tensor(1316.)\n",
      "tensor(5.)\n",
      "tensor(276.)\n",
      "tensor(3.)\n",
      "tensor(1314.)\n",
      "tensor(5.)\n",
      "tensor(279.)\n",
      "tensor(8.)\n",
      "tensor(1309.)\n",
      "tensor(2.)\n",
      "tensor(272.)\n",
      "tensor(7.)\n",
      "tensor(1310.)\n",
      "tensor(9.)\n",
      "tensor(275.)\n",
      "tensor(3.)\n",
      "tensor(1314.)\n",
      "tensor(6.)\n",
      "Epoch: 371\n",
      "train loss 0.066, val loss 0.016, and val accuracy 0.994 \n",
      "F-measure: 0.9838998317718506\n",
      "tensor(278.)\n",
      "tensor(3.)\n",
      "tensor(1314.)\n",
      "tensor(3.)\n",
      "tensor(278.)\n",
      "tensor(7.)\n",
      "tensor(1310.)\n",
      "tensor(3.)\n",
      "tensor(277.)\n",
      "tensor(4.)\n",
      "tensor(1313.)\n",
      "tensor(4.)\n",
      "tensor(278.)\n",
      "tensor(5.)\n",
      "tensor(1312.)\n",
      "tensor(3.)\n",
      "tensor(278.)\n",
      "tensor(7.)\n",
      "tensor(1310.)\n",
      "tensor(3.)\n",
      "Epoch: 376\n",
      "train loss 0.046, val loss 0.019, and val accuracy 0.994 \n",
      "F-measure: 0.9823321104049683\n",
      "tensor(278.)\n",
      "tensor(4.)\n",
      "tensor(1313.)\n",
      "tensor(3.)\n",
      "tensor(278.)\n",
      "tensor(3.)\n",
      "tensor(1314.)\n",
      "tensor(3.)\n",
      "tensor(279.)\n",
      "tensor(10.)\n",
      "tensor(1307.)\n",
      "tensor(2.)\n",
      "tensor(274.)\n",
      "tensor(1.)\n",
      "tensor(1316.)\n",
      "tensor(7.)\n",
      "tensor(273.)\n",
      "tensor(1.)\n",
      "tensor(1316.)\n",
      "tensor(8.)\n",
      "Epoch: 381\n",
      "train loss 0.067, val loss 0.015, and val accuracy 0.994 \n",
      "F-measure: 0.9837837815284729\n",
      "tensor(276.)\n",
      "tensor(2.)\n",
      "tensor(1315.)\n",
      "tensor(5.)\n",
      "tensor(278.)\n",
      "tensor(14.)\n",
      "tensor(1303.)\n",
      "tensor(3.)\n",
      "tensor(275.)\n",
      "tensor(4.)\n",
      "tensor(1313.)\n",
      "tensor(6.)\n",
      "tensor(273.)\n",
      "tensor(3.)\n",
      "tensor(1314.)\n",
      "tensor(8.)\n",
      "tensor(279.)\n",
      "tensor(3.)\n",
      "tensor(1314.)\n",
      "tensor(2.)\n",
      "Epoch: 386\n",
      "train loss 0.086, val loss 0.017, and val accuracy 0.997 \n",
      "F-measure: 0.9911189675331116\n",
      "tensor(279.)\n",
      "tensor(9.)\n",
      "tensor(1308.)\n",
      "tensor(2.)\n",
      "tensor(271.)\n",
      "tensor(2.)\n",
      "tensor(1315.)\n",
      "tensor(10.)\n",
      "tensor(270.)\n",
      "tensor(1.)\n",
      "tensor(1316.)\n",
      "tensor(11.)\n",
      "tensor(278.)\n",
      "tensor(9.)\n",
      "tensor(1308.)\n",
      "tensor(3.)\n",
      "tensor(274.)\n",
      "tensor(3.)\n",
      "tensor(1314.)\n",
      "tensor(7.)\n",
      "Epoch: 391\n",
      "train loss 0.074, val loss 0.020, and val accuracy 0.994 \n",
      "F-measure: 0.9820787906646729\n",
      "tensor(271.)\n",
      "tensor(1.)\n",
      "tensor(1316.)\n",
      "tensor(10.)\n",
      "tensor(276.)\n",
      "tensor(9.)\n",
      "tensor(1308.)\n",
      "tensor(5.)\n",
      "tensor(273.)\n",
      "tensor(6.)\n",
      "tensor(1311.)\n",
      "tensor(8.)\n",
      "tensor(273.)\n",
      "tensor(4.)\n",
      "tensor(1313.)\n",
      "tensor(8.)\n",
      "tensor(275.)\n",
      "tensor(3.)\n",
      "tensor(1314.)\n",
      "tensor(6.)\n",
      "Epoch: 396\n",
      "train loss 0.061, val loss 0.018, and val accuracy 0.994 \n",
      "F-measure: 0.9838998317718506\n",
      "tensor(277.)\n",
      "tensor(6.)\n",
      "tensor(1311.)\n",
      "tensor(4.)\n",
      "tensor(276.)\n",
      "tensor(10.)\n",
      "tensor(1307.)\n",
      "tensor(5.)\n",
      "tensor(275.)\n",
      "tensor(7.)\n",
      "tensor(1310.)\n",
      "tensor(6.)\n",
      "tensor(275.)\n",
      "tensor(4.)\n",
      "tensor(1313.)\n",
      "tensor(6.)\n",
      "tensor(278.)\n",
      "tensor(14.)\n",
      "tensor(1303.)\n",
      "tensor(3.)\n",
      "Epoch: 401\n",
      "train loss 0.063, val loss 0.025, and val accuracy 0.989 \n",
      "F-measure: 0.9703316688537598\n",
      "tensor(270.)\n",
      "tensor(5.)\n",
      "tensor(1312.)\n",
      "tensor(11.)\n",
      "tensor(275.)\n",
      "tensor(6.)\n",
      "tensor(1311.)\n",
      "tensor(6.)\n",
      "tensor(278.)\n",
      "tensor(14.)\n",
      "tensor(1303.)\n",
      "tensor(3.)\n",
      "tensor(278.)\n",
      "tensor(5.)\n",
      "tensor(1312.)\n",
      "tensor(3.)\n",
      "tensor(274.)\n",
      "tensor(2.)\n",
      "tensor(1315.)\n",
      "tensor(7.)\n",
      "Epoch: 406\n",
      "train loss 0.060, val loss 0.018, and val accuracy 0.994 \n",
      "F-measure: 0.9838420152664185\n",
      "tensor(275.)\n",
      "tensor(9.)\n",
      "tensor(1308.)\n",
      "tensor(6.)\n",
      "tensor(279.)\n",
      "tensor(17.)\n",
      "tensor(1300.)\n",
      "tensor(2.)\n",
      "tensor(275.)\n",
      "tensor(3.)\n",
      "tensor(1314.)\n",
      "tensor(6.)\n",
      "tensor(275.)\n",
      "tensor(2.)\n",
      "tensor(1315.)\n",
      "tensor(6.)\n",
      "tensor(276.)\n",
      "tensor(2.)\n",
      "tensor(1315.)\n",
      "tensor(5.)\n",
      "Epoch: 411\n",
      "train loss 0.072, val loss 0.015, and val accuracy 0.996 \n",
      "F-measure: 0.9874776601791382\n",
      "tensor(275.)\n",
      "tensor(3.)\n",
      "tensor(1314.)\n",
      "tensor(6.)\n",
      "tensor(276.)\n",
      "tensor(4.)\n",
      "tensor(1313.)\n",
      "tensor(5.)\n",
      "tensor(277.)\n",
      "tensor(2.)\n",
      "tensor(1315.)\n",
      "tensor(4.)\n",
      "tensor(276.)\n",
      "tensor(2.)\n",
      "tensor(1315.)\n",
      "tensor(5.)\n",
      "tensor(278.)\n",
      "tensor(4.)\n",
      "tensor(1313.)\n",
      "tensor(3.)\n",
      "Epoch: 416\n",
      "train loss 0.045, val loss 0.017, and val accuracy 0.996 \n",
      "F-measure: 0.9875666499137878\n",
      "tensor(278.)\n",
      "tensor(6.)\n",
      "tensor(1311.)\n",
      "tensor(3.)\n",
      "tensor(278.)\n",
      "tensor(3.)\n",
      "tensor(1314.)\n",
      "tensor(3.)\n",
      "tensor(277.)\n",
      "tensor(2.)\n",
      "tensor(1315.)\n",
      "tensor(4.)\n",
      "tensor(279.)\n",
      "tensor(4.)\n",
      "tensor(1313.)\n",
      "tensor(2.)\n",
      "tensor(279.)\n",
      "tensor(3.)\n",
      "tensor(1314.)\n",
      "tensor(2.)\n",
      "Epoch: 421\n",
      "train loss 0.042, val loss 0.012, and val accuracy 0.997 \n",
      "F-measure: 0.9911189675331116\n",
      "tensor(278.)\n",
      "tensor(2.)\n",
      "tensor(1315.)\n",
      "tensor(3.)\n",
      "tensor(279.)\n",
      "tensor(5.)\n",
      "tensor(1312.)\n",
      "tensor(2.)\n",
      "tensor(279.)\n",
      "tensor(4.)\n",
      "tensor(1313.)\n",
      "tensor(2.)\n",
      "tensor(276.)\n",
      "tensor(2.)\n",
      "tensor(1315.)\n",
      "tensor(5.)\n",
      "tensor(277.)\n",
      "tensor(2.)\n",
      "tensor(1315.)\n",
      "tensor(4.)\n",
      "Epoch: 426\n",
      "train loss 0.061, val loss 0.011, and val accuracy 0.996 \n",
      "F-measure: 0.9892856478691101\n",
      "tensor(277.)\n",
      "tensor(2.)\n",
      "tensor(1315.)\n",
      "tensor(4.)\n",
      "tensor(277.)\n",
      "tensor(2.)\n",
      "tensor(1315.)\n",
      "tensor(4.)\n",
      "tensor(277.)\n",
      "tensor(2.)\n",
      "tensor(1315.)\n",
      "tensor(4.)\n",
      "tensor(276.)\n",
      "tensor(2.)\n",
      "tensor(1315.)\n",
      "tensor(5.)\n",
      "tensor(275.)\n",
      "tensor(2.)\n",
      "tensor(1315.)\n",
      "tensor(6.)\n",
      "Epoch: 431\n",
      "train loss 0.054, val loss 0.020, and val accuracy 0.995 \n",
      "F-measure: 0.9856631755828857\n",
      "tensor(276.)\n",
      "tensor(5.)\n",
      "tensor(1312.)\n",
      "tensor(5.)\n",
      "tensor(278.)\n",
      "tensor(10.)\n",
      "tensor(1307.)\n",
      "tensor(3.)\n",
      "tensor(274.)\n",
      "tensor(4.)\n",
      "tensor(1313.)\n",
      "tensor(7.)\n",
      "tensor(276.)\n",
      "tensor(4.)\n",
      "tensor(1313.)\n",
      "tensor(5.)\n",
      "tensor(277.)\n",
      "tensor(7.)\n",
      "tensor(1310.)\n",
      "tensor(4.)\n",
      "Epoch: 436\n",
      "train loss 0.058, val loss 0.020, and val accuracy 0.993 \n",
      "F-measure: 0.9805309176445007\n",
      "tensor(275.)\n",
      "tensor(3.)\n",
      "tensor(1314.)\n",
      "tensor(6.)\n",
      "tensor(269.)\n",
      "tensor(2.)\n",
      "tensor(1315.)\n",
      "tensor(12.)\n",
      "tensor(277.)\n",
      "tensor(5.)\n",
      "tensor(1312.)\n",
      "tensor(4.)\n",
      "tensor(276.)\n",
      "tensor(4.)\n",
      "tensor(1313.)\n",
      "tensor(5.)\n",
      "tensor(269.)\n",
      "tensor(2.)\n",
      "tensor(1315.)\n",
      "tensor(12.)\n",
      "Epoch: 441\n",
      "train loss 0.066, val loss 0.021, and val accuracy 0.991 \n",
      "F-measure: 0.9746376872062683\n",
      "tensor(279.)\n",
      "tensor(8.)\n",
      "tensor(1309.)\n",
      "tensor(2.)\n",
      "tensor(278.)\n",
      "tensor(9.)\n",
      "tensor(1308.)\n",
      "tensor(3.)\n",
      "tensor(276.)\n",
      "tensor(4.)\n",
      "tensor(1313.)\n",
      "tensor(5.)\n",
      "tensor(275.)\n",
      "tensor(4.)\n",
      "tensor(1313.)\n",
      "tensor(6.)\n",
      "tensor(277.)\n",
      "tensor(10.)\n",
      "tensor(1307.)\n",
      "tensor(4.)\n",
      "Epoch: 446\n",
      "train loss 0.065, val loss 0.023, and val accuracy 0.991 \n",
      "F-measure: 0.9753521084785461\n",
      "tensor(277.)\n",
      "tensor(17.)\n",
      "tensor(1300.)\n",
      "tensor(4.)\n",
      "tensor(267.)\n",
      "tensor(6.)\n",
      "tensor(1311.)\n",
      "tensor(14.)\n",
      "tensor(270.)\n",
      "tensor(3.)\n",
      "tensor(1314.)\n",
      "tensor(11.)\n",
      "tensor(280.)\n",
      "tensor(11.)\n",
      "tensor(1306.)\n",
      "tensor(1.)\n",
      "tensor(276.)\n",
      "tensor(4.)\n",
      "tensor(1313.)\n",
      "tensor(5.)\n",
      "Epoch: 451\n",
      "train loss 0.079, val loss 0.019, and val accuracy 0.994 \n",
      "F-measure: 0.9839572310447693\n",
      "tensor(272.)\n",
      "tensor(5.)\n",
      "tensor(1312.)\n",
      "tensor(9.)\n",
      "tensor(277.)\n",
      "tensor(15.)\n",
      "tensor(1302.)\n",
      "tensor(4.)\n",
      "tensor(265.)\n",
      "tensor(7.)\n",
      "tensor(1310.)\n",
      "tensor(16.)\n",
      "tensor(276.)\n",
      "tensor(30.)\n",
      "tensor(1287.)\n",
      "tensor(5.)\n",
      "tensor(242.)\n",
      "tensor(1.)\n",
      "tensor(1316.)\n",
      "tensor(39.)\n",
      "Epoch: 456\n",
      "train loss 0.146, val loss 0.060, and val accuracy 0.975 \n",
      "F-measure: 0.9236640930175781\n",
      "tensor(269.)\n",
      "tensor(20.)\n",
      "tensor(1297.)\n",
      "tensor(12.)\n",
      "tensor(270.)\n",
      "tensor(41.)\n",
      "tensor(1276.)\n",
      "tensor(11.)\n",
      "tensor(219.)\n",
      "tensor(11.)\n",
      "tensor(1306.)\n",
      "tensor(62.)\n",
      "tensor(261.)\n",
      "tensor(78.)\n",
      "tensor(1239.)\n",
      "tensor(20.)\n",
      "tensor(217.)\n",
      "tensor(5.)\n",
      "tensor(1312.)\n",
      "tensor(64.)\n",
      "Epoch: 461\n",
      "train loss 0.227, val loss 0.115, and val accuracy 0.957 \n",
      "F-measure: 0.8628230690956116\n",
      "tensor(208.)\n",
      "tensor(11.)\n",
      "tensor(1306.)\n",
      "tensor(73.)\n",
      "tensor(231.)\n",
      "tensor(23.)\n",
      "tensor(1294.)\n",
      "tensor(50.)\n",
      "tensor(212.)\n",
      "tensor(3.)\n",
      "tensor(1314.)\n",
      "tensor(69.)\n",
      "tensor(242.)\n",
      "tensor(23.)\n",
      "tensor(1294.)\n",
      "tensor(39.)\n",
      "tensor(234.)\n",
      "tensor(10.)\n",
      "tensor(1307.)\n",
      "tensor(47.)\n",
      "Epoch: 466\n",
      "train loss 0.192, val loss 0.104, and val accuracy 0.964 \n",
      "F-measure: 0.8914284706115723\n",
      "tensor(231.)\n",
      "tensor(14.)\n",
      "tensor(1303.)\n",
      "tensor(50.)\n",
      "tensor(246.)\n",
      "tensor(29.)\n",
      "tensor(1288.)\n",
      "tensor(35.)\n",
      "tensor(222.)\n",
      "tensor(5.)\n",
      "tensor(1312.)\n",
      "tensor(59.)\n",
      "tensor(235.)\n",
      "tensor(11.)\n",
      "tensor(1306.)\n",
      "tensor(46.)\n",
      "tensor(235.)\n",
      "tensor(11.)\n",
      "tensor(1306.)\n",
      "tensor(46.)\n",
      "Epoch: 471\n",
      "train loss 0.153, val loss 0.088, and val accuracy 0.964 \n",
      "F-measure: 0.8918405771255493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(223.)\n",
      "tensor(3.)\n",
      "tensor(1314.)\n",
      "tensor(58.)\n",
      "tensor(234.)\n",
      "tensor(7.)\n",
      "tensor(1310.)\n",
      "tensor(47.)\n",
      "tensor(246.)\n",
      "tensor(8.)\n",
      "tensor(1309.)\n",
      "tensor(35.)\n",
      "tensor(246.)\n",
      "tensor(4.)\n",
      "tensor(1313.)\n",
      "tensor(35.)\n",
      "tensor(238.)\n",
      "tensor(3.)\n",
      "tensor(1314.)\n",
      "tensor(43.)\n",
      "Epoch: 476\n",
      "train loss 0.132, val loss 0.074, and val accuracy 0.971 \n",
      "F-measure: 0.9118773341178894\n",
      "tensor(260.)\n",
      "tensor(15.)\n",
      "tensor(1302.)\n",
      "tensor(21.)\n",
      "tensor(254.)\n",
      "tensor(6.)\n",
      "tensor(1311.)\n",
      "tensor(27.)\n",
      "tensor(243.)\n",
      "tensor(2.)\n",
      "tensor(1315.)\n",
      "tensor(38.)\n",
      "tensor(255.)\n",
      "tensor(8.)\n",
      "tensor(1309.)\n",
      "tensor(26.)\n",
      "tensor(261.)\n",
      "tensor(10.)\n",
      "tensor(1307.)\n",
      "tensor(20.)\n",
      "Epoch: 481\n",
      "train loss 0.096, val loss 0.054, and val accuracy 0.981 \n",
      "F-measure: 0.9456521272659302\n",
      "tensor(236.)\n",
      "tensor(3.)\n",
      "tensor(1314.)\n",
      "tensor(45.)\n",
      "tensor(253.)\n",
      "tensor(6.)\n",
      "tensor(1311.)\n",
      "tensor(28.)\n",
      "tensor(263.)\n",
      "tensor(10.)\n",
      "tensor(1307.)\n",
      "tensor(18.)\n",
      "tensor(251.)\n",
      "tensor(3.)\n",
      "tensor(1314.)\n",
      "tensor(30.)\n",
      "tensor(251.)\n",
      "tensor(3.)\n",
      "tensor(1314.)\n",
      "tensor(30.)\n",
      "Epoch: 486\n",
      "train loss 0.106, val loss 0.054, and val accuracy 0.979 \n",
      "F-measure: 0.9383177161216736\n",
      "tensor(261.)\n",
      "tensor(8.)\n",
      "tensor(1309.)\n",
      "tensor(20.)\n",
      "tensor(259.)\n",
      "tensor(7.)\n",
      "tensor(1310.)\n",
      "tensor(22.)\n",
      "tensor(257.)\n",
      "tensor(3.)\n",
      "tensor(1314.)\n",
      "tensor(24.)\n",
      "tensor(264.)\n",
      "tensor(10.)\n",
      "tensor(1307.)\n",
      "tensor(17.)\n",
      "tensor(263.)\n",
      "tensor(9.)\n",
      "tensor(1308.)\n",
      "tensor(18.)\n",
      "Epoch: 491\n",
      "train loss 0.078, val loss 0.047, and val accuracy 0.983 \n",
      "F-measure: 0.9511753916740417\n",
      "tensor(257.)\n",
      "tensor(4.)\n",
      "tensor(1313.)\n",
      "tensor(24.)\n",
      "tensor(270.)\n",
      "tensor(6.)\n",
      "tensor(1311.)\n",
      "tensor(11.)\n",
      "tensor(274.)\n",
      "tensor(13.)\n",
      "tensor(1304.)\n",
      "tensor(7.)\n",
      "tensor(269.)\n",
      "tensor(2.)\n",
      "tensor(1315.)\n",
      "tensor(12.)\n",
      "tensor(263.)\n",
      "tensor(2.)\n",
      "tensor(1315.)\n",
      "tensor(18.)\n",
      "Epoch: 496\n",
      "train loss 0.078, val loss 0.036, and val accuracy 0.987 \n",
      "F-measure: 0.9633699655532837\n",
      "tensor(272.)\n",
      "tensor(4.)\n",
      "tensor(1313.)\n",
      "tensor(9.)\n",
      "tensor(272.)\n",
      "tensor(5.)\n",
      "tensor(1312.)\n",
      "tensor(9.)\n",
      "tensor(265.)\n",
      "tensor(4.)\n",
      "tensor(1313.)\n",
      "tensor(16.)\n"
     ]
    }
   ],
   "source": [
    "loss_list, f_list = train_model(model_variable_v2_4, test_dl, epochs=500, lr=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plot the cost\n",
    "plt.plot(loss_list)\n",
    "plt.ylabel('cost')\n",
    "plt.xlabel('iterations (x1,000)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plot the cost\n",
    "plt.plot(f_list)\n",
    "plt.ylabel('cost')\n",
    "plt.xlabel('iterations (x1,000)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "def load_model(directory):\n",
    "    \n",
    "    today = datetime.datetime.now().strftime(\"%x\").replace(\"/\",\"_\")\n",
    "    directory = \"models/\"+today+\"/\"+directory\n",
    "    files = glob.glob(directory+\"/*\")\n",
    "    models = []\n",
    "    highest_f = 0\n",
    "    highest_f_index = 0\n",
    "    index = 0\n",
    "    for file in files:\n",
    "    \n",
    "        model = LSTM_variable_input_v2(CODE_WEIGHT_METRIX, TITLE_WEIGHT_METRIX,\n",
    "            HIDDEN_DIM,\n",
    "            N_LAYERS, \n",
    "            BIDIRECTIONAL)\n",
    "        model.to(device)\n",
    "        \n",
    "\n",
    "        checkpoint = torch.load(file)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        epoch = checkpoint['epoch']\n",
    "        loss = checkpoint['loss']\n",
    "        val_f_measure = checkpoint['val_f_measure']\n",
    "        \n",
    "        if highest_f < val_f_measure:\n",
    "            highest_f = val_f_measure\n",
    "            highest_f_index = index\n",
    "        index = index+1\n",
    "        models.append(model)\n",
    "\n",
    "    model = models[highest_f_index]\n",
    "        \n",
    "    return model,highest_f\n",
    "\n",
    "directory = \"17_20_06\"\n",
    "\n",
    "loaded_model, f = load_model(directory) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM_variable_input_v2(\n",
       "  (code_embedding): Embedding(1818, 50)\n",
       "  (title_embedding): Embedding(818, 50)\n",
       "  (code_lstm): LSTM(50, 50, num_layers=2, dropout=0.3, bidirectional=True)\n",
       "  (title_lstm): LSTM(50, 50, num_layers=2, dropout=0.3, bidirectional=True)\n",
       "  (linear): Linear(in_features=100, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9911189675331116"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(279.)\n",
      "tensor(3.)\n",
      "tensor(1314.)\n",
      "tensor(2.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nimmi/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/nimmi/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:516: UserWarning: Using a target size (torch.Size([1000])) that is different to the input size (torch.Size([1000, 1])) is deprecated. Please ensure they have the same size.\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n",
      "/home/nimmi/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:516: UserWarning: Using a target size (torch.Size([598])) that is different to the input size (torch.Size([598, 1])) is deprecated. Please ensure they have the same size.\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.017087815562554533,\n",
       " tensor(0.9969),\n",
       " {'precision': 0.9893617033958435,\n",
       "  'recall': 0.9928825497627258,\n",
       "  'f_measure': 0.9911189675331116,\n",
       "  'accuracy': 0.9968711137771606})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_metrics (loaded_model, test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nimmi/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "pred_list = []\n",
    "y_list = []\n",
    "for x1,x2,y,l1,l2 in test_dl:\n",
    "        x1 = x1.long()\n",
    "        x2 = x2.long()\n",
    "        y = y.long()\n",
    "        y = y.flatten()\n",
    "        y = torch.tensor(y, dtype=torch.float)  \n",
    "        \n",
    "        #x1,x2,y,l1,l2 = x1.to(device), x2.to(device), y.to(device), l1.to(device), l2.to(device)\n",
    "        x1,x2,l1,l2 = x1.to(device), x2.to(device), l1.to(device), l2.to(device)\n",
    "\n",
    "        \n",
    "        y_hat = loaded_model(x1, x2,l1,l2)\n",
    "        y_hat = y_hat.cpu()\n",
    "        \n",
    "        loss = nn.BCELoss()(y_hat, y)\n",
    "        #loss = nn.BCEWithLogitsLoss()(y_hat, y.reshape(-1,1))\n",
    "        #print(y_hat)\n",
    "        pred = (y_hat>0.5).float()\n",
    "        pred_list.append(pred)\n",
    "        y_list.append(y)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_pred_list=[]\n",
    "for t in pred_list:\n",
    "    _pred_list = _pred_list+t.reshape(-1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "_y_list=[]\n",
    "for t in y_list:\n",
    "    _y_list = _y_list+t.reshape(-1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_codes = codes[codes['is_golden']==1]['token_numbers'].values\n",
    "X_test_titles = codes[codes['is_golden']==1]['title_token_numbers'].values\n",
    "y_test = codes[codes['is_golden']==1]['is_idiomatic'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1598"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 0, 0, 0, 0, 0, 1, 0]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(y_test[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ParentId_x', 'PostId', 'PostHistoryId', 'LocalId', 'PostBlockTypeId',\n",
       "       'Length', 'LineCount', 'Content', 'is_idiomatic', 'is_golden',\n",
       "       'is_golden_idiom', 'text', 'tokens', 'Id', 'PostTypeId',\n",
       "       'AcceptedAnswerId', 'ParentId_y', 'CreationDate', 'DeletionDate',\n",
       "       'ViewCount', 'Body', 'OwnerUserId', 'OwnerDisplayName',\n",
       "       'LastEditorUserId', 'LastEditorDisplayName', 'LastEditDate',\n",
       "       'LastActivityDate', 'Title', 'Tags', 'AnswerCount', 'CommentCount',\n",
       "       'FavoriteCount', 'ClosedDate', 'CommunityOwnedDate', 'title_tokens',\n",
       "       'QuestionScore', 'ParentId', 'AcceptedAnswerScore', 'Score',\n",
       "       'code_length', 'token_numbers', 'title_token_numbers'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codes.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nimmi/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/home/nimmi/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "val_data = codes.loc[codes['is_golden']==1]\n",
    "val_data['pred']=_pred_list\n",
    "val_data['y']=_y_list\n",
    "d = val_data[['Title','Content','Score', 'AcceptedAnswerScore','pred','y','ParentId_x','PostId','LocalId','AcceptedAnswerId','is_idiomatic']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1598\n",
      "1598\n"
     ]
    }
   ],
   "source": [
    "print(len(d[d['is_idiomatic']==d['y']]))\n",
    "print(len(d)) #sanity check passed :P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------\n",
      "----------------------------------------------\n",
      "JavaScript for...in vs for\n",
      "https://stackoverflow.com/questions/242841\n",
      "Score: 545\n",
      "PostId: 242888\n",
      "LocalId: 2\n",
      "AcceptedAnswerScore: 545\n",
      "AcceptedAnswer: True\n",
      "AcceptedAnswer: 242888.0\n",
      "----------------------------------------------\n",
      "    for (var i = 0; i < a.length; i++)\n",
      "       //do stuff with a[i]\n",
      "----------------------------------------------\n",
      "----------------------------------------------\n",
      "JavaScript for...in vs for\n",
      "https://stackoverflow.com/questions/242841\n",
      "Score: 545\n",
      "PostId: 242888\n",
      "LocalId: 4\n",
      "AcceptedAnswerScore: 545\n",
      "AcceptedAnswer: True\n",
      "AcceptedAnswer: 242888.0\n",
      "----------------------------------------------\n",
      "    for (var key in o)\n",
      "      //do stuff with o[key]\n",
      "----------------------------------------------\n",
      "----------------------------------------------\n",
      "Get the name of an object's type\n",
      "https://stackoverflow.com/questions/332422\n",
      "Score: 1527\n",
      "PostId: 332429\n",
      "LocalId: 4\n",
      "AcceptedAnswerScore: 1527\n",
      "AcceptedAnswer: True\n",
      "AcceptedAnswer: 332429.0\n",
      "----------------------------------------------\n",
      "    var myArray = [1,2,3];\n",
      "    (myArray.constructor == Array); // true\n",
      "----------------------------------------------\n",
      "----------------------------------------------\n",
      "Is JavaScript's \"new\" keyword considered harmful?\n",
      "https://stackoverflow.com/questions/383402\n",
      "Score: 601\n",
      "PostId: 383503\n",
      "LocalId: 4\n",
      "AcceptedAnswerScore: 601\n",
      "AcceptedAnswer: True\n",
      "AcceptedAnswer: 383503.0\n",
      "----------------------------------------------\n",
      "    if ( !(this instanceof arguments.callee) ) \n",
      "       throw new Error(\"Constructor called as a function\");\n",
      "----------------------------------------------\n",
      "----------------------------------------------\n",
      "How to check if object has any properties in JavaScript?\n",
      "https://stackoverflow.com/questions/2673121\n",
      "Score: 85\n",
      "PostId: 2673141\n",
      "LocalId: 2\n",
      "AcceptedAnswerScore: 85\n",
      "AcceptedAnswer: True\n",
      "AcceptedAnswer: 2673141.0\n",
      "----------------------------------------------\n",
      "    for(var prop in ad) {\n",
      "        if (ad.hasOwnProperty(prop)) {\n",
      "            // handle prop as required\n",
      "        }\n",
      "    }\n",
      "----------------------------------------------\n",
      "----------------------------------------------\n",
      "How to check if object has any properties in JavaScript?\n",
      "https://stackoverflow.com/questions/2673121\n",
      "Score: 168\n",
      "PostId: 39565817\n",
      "LocalId: 2\n",
      "AcceptedAnswerScore: 85\n",
      "AcceptedAnswer: False\n",
      "AcceptedAnswer: 2673141.0\n",
      "----------------------------------------------\n",
      "    var x = {};\n",
      "    // some code where value of x changes and than you want to check whether it is null or some object with values\n",
      "    \n",
      "    if(Object.keys(x).length > 0){\n",
      "     // Your code here if x has some properties  \n",
      "    }\n",
      "----------------------------------------------\n",
      "----------------------------------------------\n",
      "Getting JavaScript object key list\n",
      "https://stackoverflow.com/questions/3068534\n",
      "Score: 339\n",
      "PostId: 3068542\n",
      "LocalId: 1\n",
      "AcceptedAnswerScore: 339\n",
      "AcceptedAnswer: True\n",
      "AcceptedAnswer: 3068542.0\n",
      "----------------------------------------------\n",
      "    var obj = {\n",
      "       key1: 'value1',\n",
      "       key2: 'value2',\n",
      "       key3: 'value3',\n",
      "       key4: 'value4'\n",
      "    };\n",
      "    var keys = [];\n",
      "    for (var k in obj) keys.push(k);\n",
      "    alert(\"total \" + keys.length + \" keys: \" + keys);\n",
      "----------------------------------------------\n",
      "----------------------------------------------\n",
      "Getting a random value from a JavaScript array\n",
      "https://stackoverflow.com/questions/4550505\n",
      "Score: 1399\n",
      "PostId: 4550514\n",
      "LocalId: 4\n",
      "AcceptedAnswerScore: 1399\n",
      "AcceptedAnswer: True\n",
      "AcceptedAnswer: 4550514.0\n",
      "----------------------------------------------\n",
      "    const months = [\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"];\n",
      "    const randomMonth = months[Math.floor(Math.random() * months.length)];\n",
      "    \n",
      "    console.log(\"random month =>\", randomMonth);\n",
      "----------------------------------------------\n",
      "----------------------------------------------\n",
      "How to include js file in another js file?\n",
      "https://stackoverflow.com/questions/4634644\n",
      "Score: 266\n",
      "PostId: 4634669\n",
      "LocalId: 2\n",
      "AcceptedAnswerScore: 266\n",
      "AcceptedAnswer: True\n",
      "AcceptedAnswer: 4634669.0\n",
      "----------------------------------------------\n",
      "    var imported = document.createElement('script');\n",
      "    imported.src = '/path/to/imported/script';\n",
      "    document.head.appendChild(imported);\n",
      "    \n",
      "----------------------------------------------\n",
      "----------------------------------------------\n",
      "How to include js file in another js file?\n",
      "https://stackoverflow.com/questions/4634644\n",
      "Score: 266\n",
      "PostId: 4634669\n",
      "LocalId: 4\n",
      "AcceptedAnswerScore: 266\n",
      "AcceptedAnswer: True\n",
      "AcceptedAnswer: 4634669.0\n",
      "----------------------------------------------\n",
      "    // jQuery\n",
      "    $.getScript('/path/to/imported/script.js', function()\n",
      "    {\n",
      "    \t// script is now loaded and executed.\n",
      "    \t// put your dependent JS here.\n",
      "    });\n",
      "----------------------------------------------\n",
      "----------------------------------------------\n",
      "Difference between variable declaration syntaxes in Javascript (including global variables)?\n",
      "https://stackoverflow.com/questions/4862193\n",
      "Score: 555\n",
      "PostId: 4862268\n",
      "LocalId: 6\n",
      "AcceptedAnswerScore: 555\n",
      "AcceptedAnswer: True\n",
      "AcceptedAnswer: 4862268.0\n",
      "----------------------------------------------\n",
      "    try {\n",
      "        delete window.prop;\n",
      "    }\n",
      "    catch (e) {\n",
      "        window.prop = undefined;\n",
      "    }\n",
      "----------------------------------------------\n",
      "----------------------------------------------\n",
      "How to capitalize first letter of each word, like a 2-word city?\n",
      "https://stackoverflow.com/questions/4878756\n",
      "Score: 640\n",
      "PostId: 4878800\n",
      "LocalId: 4\n",
      "AcceptedAnswerScore: 640\n",
      "AcceptedAnswer: True\n",
      "AcceptedAnswer: 4878800.0\n",
      "----------------------------------------------\n",
      "    var text = \"foo bar loo zoo moo\";\n",
      "    text = text.toLowerCase()\n",
      "        .split(' ')\n",
      "        .map((s) => s.charAt(0).toUpperCase() + s.substring(1))\n",
      "        .join(' ');\n",
      "----------------------------------------------\n",
      "----------------------------------------------\n",
      "How to append data to div using JavaScript?\n",
      "https://stackoverflow.com/questions/5677799\n",
      "Score: 559\n",
      "PostId: 5677816\n",
      "LocalId: 2\n",
      "AcceptedAnswerScore: 559\n",
      "AcceptedAnswer: True\n",
      "AcceptedAnswer: 5677816.0\n",
      "----------------------------------------------\n",
      "    var div = document.getElementById('divID');\n",
      "    \n",
      "    div.innerHTML += 'Extra stuff';\n",
      "----------------------------------------------\n",
      "----------------------------------------------\n",
      "Check if a variable is of function type\n",
      "https://stackoverflow.com/questions/5999998\n",
      "Score: 1653\n",
      "PostId: 6000009\n",
      "LocalId: 1\n",
      "AcceptedAnswerScore: 367\n",
      "AcceptedAnswer: False\n",
      "AcceptedAnswer: 7356528.0\n",
      "----------------------------------------------\n",
      "    if (typeof v === \"function\") {\n",
      "        // do something\n",
      "    }\n",
      "----------------------------------------------\n",
      "----------------------------------------------\n",
      "How to check if function exists in JavaScript?\n",
      "https://stackoverflow.com/questions/1042138\n",
      "Score: 1170\n",
      "PostId: 1042154\n",
      "LocalId: 2\n",
      "AcceptedAnswerScore: 1170\n",
      "AcceptedAnswer: True\n",
      "AcceptedAnswer: 1042154.0\n",
      "----------------------------------------------\n",
      "    if (typeof me.onChange !== \"undefined\") { \n",
      "        // safe to use the function\n",
      "    }\n",
      "----------------------------------------------\n",
      "----------------------------------------------\n",
      "How to check if function exists in JavaScript?\n",
      "https://stackoverflow.com/questions/1042138\n",
      "Score: 1170\n",
      "PostId: 1042154\n",
      "LocalId: 4\n",
      "AcceptedAnswerScore: 1170\n",
      "AcceptedAnswer: True\n",
      "AcceptedAnswer: 1042154.0\n",
      "----------------------------------------------\n",
      "    if (typeof me.onChange === \"function\") { \n",
      "        // safe to use the function\n",
      "    }\n",
      "----------------------------------------------\n",
      "----------------------------------------------\n",
      "Mimicking sets in JavaScript?\n",
      "https://stackoverflow.com/questions/7958292\n",
      "Score: 262\n",
      "PostId: 7958422\n",
      "LocalId: 4\n",
      "AcceptedAnswerScore: 262\n",
      "AcceptedAnswer: True\n",
      "AcceptedAnswer: 7958422.0\n",
      "----------------------------------------------\n",
      "    if (A in obj) {\n",
      "        // put code here\n",
      "    }\n",
      "----------------------------------------------\n",
      "----------------------------------------------\n",
      "Mimicking sets in JavaScript?\n",
      "https://stackoverflow.com/questions/7958292\n",
      "Score: 262\n",
      "PostId: 7958422\n",
      "LocalId: 10\n",
      "AcceptedAnswerScore: 262\n",
      "AcceptedAnswer: True\n",
      "AcceptedAnswer: 7958422.0\n",
      "----------------------------------------------\n",
      "    if (Object.prototype.hasOwnProperty.call(obj, A))\n",
      "        // put code here\n",
      "    }\n",
      "----------------------------------------------\n",
      "----------------------------------------------\n",
      "How to calculate number of days between two dates\n",
      "https://stackoverflow.com/questions/9129928\n",
      "Score: 621\n",
      "PostId: 9130040\n",
      "LocalId: 2\n",
      "AcceptedAnswerScore: 621\n",
      "AcceptedAnswer: True\n",
      "AcceptedAnswer: 9130040.0\n",
      "----------------------------------------------\n",
      "    var a = moment([2007, 0, 29]);\n",
      "    var b = moment([2007, 0, 28]);\n",
      "    a.diff(b, 'days')   // =1\n",
      "----------------------------------------------\n",
      "----------------------------------------------\n",
      "Is it possible to stop JavaScript execution?\n",
      "https://stackoverflow.com/questions/9298839\n",
      "Score: 511\n",
      "PostId: 9298915\n",
      "LocalId: 8\n",
      "AcceptedAnswerScore: 511\n",
      "AcceptedAnswer: True\n",
      "AcceptedAnswer: 9298915.0\n",
      "----------------------------------------------\n",
      "    if(someEventHappened) return; // Will prevent subsequent code from being executed\n",
      "    alert(\"This alert will never be shown.\");\n",
      "----------------------------------------------\n",
      "----------------------------------------------\n",
      "JavaScript set object key by variable\n",
      "https://stackoverflow.com/questions/11508463\n",
      "Score: 1611\n",
      "PostId: 11508490\n",
      "LocalId: 2\n",
      "AcceptedAnswerScore: 1611\n",
      "AcceptedAnswer: True\n",
      "AcceptedAnswer: 11508490.0\n",
      "----------------------------------------------\n",
      "    var key = \"happyCount\";\n",
      "    var obj = {};\n",
      "    obj[key] = someValueArray;\n",
      "    myArray.push(obj);\n",
      "----------------------------------------------\n",
      "----------------------------------------------\n",
      "How to check if a variable is an integer in JavaScript?\n",
      "https://stackoverflow.com/questions/14636536\n",
      "Score: 334\n",
      "PostId: 14636652\n",
      "LocalId: 2\n",
      "AcceptedAnswerScore: 334\n",
      "AcceptedAnswer: True\n",
      "AcceptedAnswer: 14636652.0\n",
      "----------------------------------------------\n",
      "    if (data === parseInt(data, 10))\n",
      "        alert(\"data is integer\")\n",
      "    else\n",
      "        alert(\"data is not an integer\")\n",
      "----------------------------------------------\n",
      "----------------------------------------------\n",
      "push multiple elements to array\n",
      "https://stackoverflow.com/questions/14723848\n",
      "Score: 399\n",
      "PostId: 35167699\n",
      "LocalId: 2\n",
      "AcceptedAnswerScore: 224\n",
      "AcceptedAnswer: False\n",
      "AcceptedAnswer: 14723909.0\n",
      "----------------------------------------------\n",
      "    var arr = [1];\n",
      "    var newItems = [2, 3];\n",
      "    arr.push(...newItems);\n",
      "    console.log(arr);\n",
      "----------------------------------------------\n",
      "----------------------------------------------\n",
      "How to get height of entire document with JavaScript?\n",
      "https://stackoverflow.com/questions/1145850\n",
      "Score: 652\n",
      "PostId: 1147768\n",
      "LocalId: 2\n",
      "AcceptedAnswerScore: 652\n",
      "AcceptedAnswer: True\n",
      "AcceptedAnswer: 1147768.0\n",
      "----------------------------------------------\n",
      "    var body = document.body,\n",
      "        html = document.documentElement;\n",
      "    var height = Math.max( body.scrollHeight, body.offsetHeight, \n",
      "                           html.clientHeight, html.scrollHeight, html.offsetHeight );\n",
      "----------------------------------------------\n",
      "----------------------------------------------\n",
      "Check if a variable is a string in JavaScript\n",
      "https://stackoverflow.com/questions/4059147\n",
      "Score: 1831\n",
      "PostId: 9436948\n",
      "LocalId: 2\n",
      "AcceptedAnswerScore: 1579\n",
      "AcceptedAnswer: False\n",
      "AcceptedAnswer: 4059166.0\n",
      "----------------------------------------------\n",
      "    if (typeof myVar === 'string' || myVar instanceof String)\n",
      "    // it's a string\n",
      "    else\n",
      "    // it's something else\n",
      "----------------------------------------------\n",
      "----------------------------------------------\n",
      "How to loop through a plain JavaScript object with the objects as members?\n",
      "https://stackoverflow.com/questions/921789\n",
      "Score: 2086\n",
      "PostId: 921808\n",
      "LocalId: 1\n",
      "AcceptedAnswerScore: 2086\n",
      "AcceptedAnswer: True\n",
      "AcceptedAnswer: 921808.0\n",
      "----------------------------------------------\n",
      "\tfor (var key in validation_messages) {\n",
      "\t\t// skip loop if the property is from prototype\n",
      "\t\tif (!validation_messages.hasOwnProperty(key)) continue;\n",
      "\t\n",
      "\t\tvar obj = validation_messages[key];\n",
      "\t\tfor (var prop in obj) {\n",
      "\t\t\t// skip loop if the property is from prototype\n",
      "\t\t\tif (!obj.hasOwnProperty(prop)) continue;\n",
      "\t\n",
      "\t\t\t// your code\n",
      "\t\t\talert(prop + \" = \" + obj[prop]);\n",
      "\t\t}\n",
      "\t}\n",
      "----------------------------------------------\n",
      "----------------------------------------------\n",
      "Object.getOwnPropertyNames vs Object.keys\n",
      "https://stackoverflow.com/questions/22658488\n",
      "Score: 276\n",
      "PostId: 22658584\n",
      "LocalId: 2\n",
      "AcceptedAnswerScore: 276\n",
      "AcceptedAnswer: True\n",
      "AcceptedAnswer: 22658584.0\n",
      "----------------------------------------------\n",
      "    var a = {};\n",
      "    Object.defineProperties(a, {\n",
      "        one: {enumerable: true, value: 'one'},\n",
      "        two: {enumerable: false, value: 'two'},\n",
      "    });\n",
      "    Object.keys(a); // [\"one\"]\n",
      "    Object.getOwnPropertyNames(a); // [\"one\", \"two\"]\n",
      "----------------------------------------------\n",
      "----------------------------------------------\n",
      "JavaScript: location.href to open in new window/tab?\n",
      "https://stackoverflow.com/questions/5141910\n",
      "Score: 908\n",
      "PostId: 5141926\n",
      "LocalId: 1\n",
      "AcceptedAnswerScore: 908\n",
      "AcceptedAnswer: True\n",
      "AcceptedAnswer: 5141926.0\n",
      "----------------------------------------------\n",
      "    window.open(\n",
      "      'https://support.wwf.org.uk/earth_hour/index.php?type=individual',\n",
      "      '_blank' // <- This is what makes it open in a new window.\n",
      "    );\n",
      "----------------------------------------------\n",
      "----------------------------------------------\n",
      "Getting All Variables In Scope\n",
      "https://stackoverflow.com/questions/2051678\n",
      "Score: 83\n",
      "PostId: 2051693\n",
      "LocalId: 2\n",
      "AcceptedAnswerScore: 83\n",
      "AcceptedAnswer: True\n",
      "AcceptedAnswer: 2051693.0\n",
      "----------------------------------------------\n",
      "    var n, arg, name;\n",
      "    alert(\"typeof this = \" + typeof this);\n",
      "    for (name in this) {\n",
      "        alert(\"this[\" + name + \"]=\" + this[name]);\n",
      "    }\n",
      "    for (n = 0; n < arguments.length; ++n) {\n",
      "        arg = arguments[n];\n",
      "        alert(\"typeof arguments[\" + n + \"] = \" + typeof arg);\n",
      "        for (name in arg) {\n",
      "            alert(\"arguments[\" + n + \"][\" + name + \"]=\" + arg[name]);\n",
      "        }\n",
      "    }\n",
      "----------------------------------------------\n",
      "----------------------------------------------\n",
      "Find mouse position relative to element\n",
      "https://stackoverflow.com/questions/3234256\n",
      "Score: 165\n",
      "PostId: 10429969\n",
      "LocalId: 2\n",
      "AcceptedAnswerScore: 165\n",
      "AcceptedAnswer: True\n",
      "AcceptedAnswer: 10429969.0\n",
      "----------------------------------------------\n",
      "    var x = evt.pageX - $('#element').offset().left;\n",
      "    var y = evt.pageY - $('#element').offset().top;\n",
      "----------------------------------------------\n",
      "----------------------------------------------\n",
      "Find mouse position relative to element\n",
      "https://stackoverflow.com/questions/3234256\n",
      "Score: 165\n",
      "PostId: 10429969\n",
      "LocalId: 4\n",
      "AcceptedAnswerScore: 165\n",
      "AcceptedAnswer: True\n",
      "AcceptedAnswer: 10429969.0\n",
      "----------------------------------------------\n",
      "    var x = (evt.pageX - $('#element').offset().left) + self.frame.scrollLeft();\n",
      "    var y = (evt.pageY - $('#element').offset().top) + self.frame.scrollTop();\n",
      "----------------------------------------------\n",
      "----------------------------------------------\n",
      "Find mouse position relative to element\n",
      "https://stackoverflow.com/questions/3234256\n",
      "Score: 165\n",
      "PostId: 10429969\n",
      "LocalId: 6\n",
      "AcceptedAnswerScore: 165\n",
      "AcceptedAnswer: True\n",
      "AcceptedAnswer: 10429969.0\n",
      "----------------------------------------------\n",
      "    var x = (evt.pageX - $('#element').offset().left) + $(window).scrollLeft();\n",
      "    var y = (evt.pageY - $('#element').offset().top) + $(window).scrollTop();\n",
      "----------------------------------------------\n",
      "----------------------------------------------\n",
      "Find mouse position relative to element\n",
      "https://stackoverflow.com/questions/3234256\n",
      "Score: 165\n",
      "PostId: 10429969\n",
      "LocalId: 8\n",
      "AcceptedAnswerScore: 165\n",
      "AcceptedAnswer: True\n",
      "AcceptedAnswer: 10429969.0\n",
      "----------------------------------------------\n",
      "    var offset = $('#element').offset();\n",
      "    // Then refer to \n",
      "    var x = evt.pageX - offset.left;\n",
      "----------------------------------------------\n",
      "----------------------------------------------\n",
      "How can I test if a letter in a string is uppercase or lowercase using JavaScript?\n",
      "https://stackoverflow.com/questions/1027224\n",
      "Score: 312\n",
      "PostId: 1077692\n",
      "LocalId: 2\n",
      "AcceptedAnswerScore: 312\n",
      "AcceptedAnswer: True\n",
      "AcceptedAnswer: 1077692.0\n",
      "----------------------------------------------\n",
      "    var character = '5';\n",
      "    if (character == character.toUpperCase()) {\n",
      "     alert ('upper case true');\n",
      "    }\n",
      "    if (character == character.toLowerCase()){\n",
      "     alert ('lower case true');\n",
      "    }\n",
      "----------------------------------------------\n",
      "----------------------------------------------\n",
      "How can I test if a letter in a string is uppercase or lowercase using JavaScript?\n",
      "https://stackoverflow.com/questions/1027224\n",
      "Score: 312\n",
      "PostId: 1077692\n",
      "LocalId: 4\n",
      "AcceptedAnswerScore: 312\n",
      "AcceptedAnswer: True\n",
      "AcceptedAnswer: 1077692.0\n",
      "----------------------------------------------\n",
      "    var strings = 'this iS a TeSt 523 Now!';\n",
      "    var i=0;\n",
      "    var character='';\n",
      "    while (i <= strings.length){\n",
      "    \tcharacter = strings.charAt(i);\n",
      "    \tif (!isNaN(character * 1)){\n",
      "    \t\talert('character is numeric');\n",
      "    \t}else{\n",
      "    \t\tif (character == character.toUpperCase()) {\n",
      "    \t\t\talert ('upper case true');\n",
      "    \t\t}\n",
      "    \t\tif (character == character.toLowerCase()){\n",
      "    \t\t\talert ('lower case true');\n",
      "    \t\t}\n",
      "    \t}\n",
      "    \ti++;\n",
      "    }\n",
      "----------------------------------------------\n",
      "----------------------------------------------\n",
      "How to get start and end of day in Javascript?\n",
      "https://stackoverflow.com/questions/8636617\n",
      "Score: 480\n",
      "PostId: 8636674\n",
      "LocalId: 1\n",
      "AcceptedAnswerScore: 480\n",
      "AcceptedAnswer: True\n",
      "AcceptedAnswer: 8636674.0\n",
      "----------------------------------------------\n",
      "    var start = new Date();\n",
      "    start.setHours(0,0,0,0);\n",
      "    \n",
      "    var end = new Date();\n",
      "    end.setHours(23,59,59,999);\n",
      "    \n",
      "    alert( start.toUTCString() + ':' + end.toUTCString() );\n",
      "----------------------------------------------\n",
      "----------------------------------------------\n",
      "How do I iterate through table rows and cells in JavaScript?\n",
      "https://stackoverflow.com/questions/3065342\n",
      "Score: 284\n",
      "PostId: 3065389\n",
      "LocalId: 2\n",
      "AcceptedAnswerScore: 284\n",
      "AcceptedAnswer: True\n",
      "AcceptedAnswer: 3065389.0\n",
      "----------------------------------------------\n",
      "    var table = document.getElementById(\"mytab1\");\n",
      "    for (var i = 0, row; row = table.rows[i]; i++) {\n",
      "       //iterate through rows\n",
      "       //rows would be accessed using the \"row\" variable assigned in the for loop\n",
      "       for (var j = 0, col; col = row.cells[j]; j++) {\n",
      "         //iterate through columns\n",
      "         //columns would be accessed using the \"col\" variable assigned in the for loop\n",
      "       }  \n",
      "    }\n",
      "----------------------------------------------\n",
      "----------------------------------------------\n",
      "How do I iterate through table rows and cells in JavaScript?\n",
      "https://stackoverflow.com/questions/3065342\n",
      "Score: 284\n",
      "PostId: 3065389\n",
      "LocalId: 4\n",
      "AcceptedAnswerScore: 284\n",
      "AcceptedAnswer: True\n",
      "AcceptedAnswer: 3065389.0\n",
      "----------------------------------------------\n",
      "    var table = document.getElementById(\"mytab1\");\n",
      "    for (var i = 0, cell; cell = table.cells[i]; i++) {\n",
      "         //iterate through cells\n",
      "         //cells would be accessed using the \"cell\" variable assigned in the for loop\n",
      "    }\n",
      "----------------------------------------------\n",
      "----------------------------------------------\n",
      "How To Set A JS object property name from a variable\n",
      "https://stackoverflow.com/questions/13833204\n",
      "Score: 184\n",
      "PostId: 13833241\n",
      "LocalId: 1\n",
      "AcceptedAnswerScore: 184\n",
      "AcceptedAnswer: True\n",
      "AcceptedAnswer: 13833241.0\n",
      "----------------------------------------------\n",
      "    var jsonVariable = {};\n",
      "    for(var i=1; i < 3; i++) {\n",
      "      jsonVariable[i + 'name'] = 'name' + i;        \n",
      "    }\n",
      "----------------------------------------------\n",
      "----------------------------------------------\n",
      "JavaScript get window X/Y position for scroll\n",
      "https://stackoverflow.com/questions/3464876\n",
      "Score: 274\n",
      "PostId: 3464890\n",
      "LocalId: 2\n",
      "AcceptedAnswerScore: 274\n",
      "AcceptedAnswer: True\n",
      "AcceptedAnswer: 3464890.0\n",
      "----------------------------------------------\n",
      "    var doc = document.documentElement;\n",
      "    var left = (window.pageXOffset || doc.scrollLeft) - (doc.clientLeft || 0);\n",
      "    var top = (window.pageYOffset || doc.scrollTop)  - (doc.clientTop || 0);\n",
      "----------------------------------------------\n",
      "----------------------------------------------\n",
      "convert '1' to '0001' in JavaScript\n",
      "https://stackoverflow.com/questions/5366849\n",
      "Score: 392\n",
      "PostId: 5366862\n",
      "LocalId: 2\n",
      "AcceptedAnswerScore: 392\n",
      "AcceptedAnswer: True\n",
      "AcceptedAnswer: 5366862.0\n",
      "----------------------------------------------\n",
      "    var str = \"\" + 1\n",
      "    var pad = \"0000\"\n",
      "    var ans = pad.substring(0, pad.length - str.length) + str\n",
      "41 code idioms detected\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "\n",
    "id_list = []\n",
    "\n",
    "for tupl in d.values:\n",
    "    title = tupl[0]\n",
    "    content = tupl[1]\n",
    "    score = tupl[2]\n",
    "    acceptedAnswerScore = tupl[3]\n",
    "    pred = tupl[4]\n",
    "    y = tupl[5]\n",
    "    parentId = tupl[6]\n",
    "    postId = tupl[7]\n",
    "    localId = tupl[8]\n",
    "    acceptedAnswerId = tupl[9]\n",
    "    if((pred==1)and(acceptedAnswerScore<=score)):\n",
    "        print(\"----------------------------------------------\")\n",
    "        print(\"----------------------------------------------\")\n",
    "        print(title)\n",
    "        print(\"https://stackoverflow.com/questions/\"+str(parentId))\n",
    "        #print(\"Y: \"+str(y))\n",
    "        print(\"Score: \"+str(score))\n",
    "        print(\"PostId: \"+str(postId))\n",
    "        print(\"LocalId: \"+str(localId))\n",
    "        print(\"AcceptedAnswerScore: \"+str(acceptedAnswerScore))\n",
    "        print(\"AcceptedAnswer: \"+str(acceptedAnswerId==postId))\n",
    "        print(\"AcceptedAnswer: \"+str(acceptedAnswerId))\n",
    "        #print(\"Predicted: \"+str(pred))\n",
    "        print(\"----------------------------------------------\")\n",
    "        \n",
    "        for line in content.split(SEPARATOR):\n",
    "            print(line)\n",
    "        id_list.append(postId)\n",
    "        i=i+1\n",
    "        \n",
    "print(str(i)+\" code idioms detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ParentId</th>\n",
       "      <th>PostId</th>\n",
       "      <th>PostHistoryId</th>\n",
       "      <th>LocalId</th>\n",
       "      <th>PostBlockTypeId</th>\n",
       "      <th>Length</th>\n",
       "      <th>IsIdiom</th>\n",
       "      <th>LineCount</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>242841</td>\n",
       "      <td>242888</td>\n",
       "      <td>19036846</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>for (var i = 0; i &lt; a.length; i++)&amp;#xD;&amp;#x...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>242841</td>\n",
       "      <td>242888</td>\n",
       "      <td>19036846</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>for (var key in o)&amp;#xD;&amp;#xA;      //do stu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1420</th>\n",
       "      <td>332422</td>\n",
       "      <td>332429</td>\n",
       "      <td>166319667</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>239</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>Object.prototype.getName = function() { &amp;#...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1422</th>\n",
       "      <td>332422</td>\n",
       "      <td>332429</td>\n",
       "      <td>166319667</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>var myArray = [1,2,3];&amp;#xD;&amp;#xA;    (myArr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1426</th>\n",
       "      <td>332422</td>\n",
       "      <td>332429</td>\n",
       "      <td>166319667</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>function a() { this.foo = 1;}&amp;#xD;&amp;#xA;   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31292</th>\n",
       "      <td>13833204</td>\n",
       "      <td>13833241</td>\n",
       "      <td>33074213</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>116</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>var jsonVariable = {};&amp;#xD;&amp;#xA;    for(va...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32204</th>\n",
       "      <td>14636536</td>\n",
       "      <td>14636652</td>\n",
       "      <td>163252848</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>118</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>if (data === parseInt(data, 10))&amp;#xD;&amp;#xA;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40243</th>\n",
       "      <td>22658488</td>\n",
       "      <td>22658584</td>\n",
       "      <td>76355388</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>235</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>var a = {};&amp;#xD;&amp;#xA;    Object.defineProp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48654</th>\n",
       "      <td>14723848</td>\n",
       "      <td>35167699</td>\n",
       "      <td>143240984</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>var arr = [1];&amp;#xD;&amp;#xA;    var newItems =...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52040</th>\n",
       "      <td>2673121</td>\n",
       "      <td>39565817</td>\n",
       "      <td>127422841</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>226</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>var x = {};&amp;#xD;&amp;#xA;    // some code wher...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ParentId    PostId  PostHistoryId  LocalId  PostBlockTypeId  Length  \\\n",
       "974      242841    242888       19036846        2                2      66   \n",
       "976      242841    242888       19036846        4                2      51   \n",
       "1420     332422    332429      166319667        2                2     239   \n",
       "1422     332422    332429      166319667        4                2      70   \n",
       "1426     332422    332429      166319667        8                2     116   \n",
       "...         ...       ...            ...      ...              ...     ...   \n",
       "31292  13833204  13833241       33074213        1                2     116   \n",
       "32204  14636536  14636652      163252848        2                2     118   \n",
       "40243  22658488  22658584       76355388        2                2     235   \n",
       "48654  14723848  35167699      143240984        2                2      94   \n",
       "52040   2673121  39565817      127422841        2                2     226   \n",
       "\n",
       "       IsIdiom  LineCount                                            Content  \n",
       "974          1          2      for (var i = 0; i < a.length; i++)&#xD;&#x...  \n",
       "976          1          2      for (var key in o)&#xD;&#xA;      //do stu...  \n",
       "1420         0          5      Object.prototype.getName = function() { &#...  \n",
       "1422         1          2      var myArray = [1,2,3];&#xD;&#xA;    (myArr...  \n",
       "1426         0          3      function a() { this.foo = 1;}&#xD;&#xA;   ...  \n",
       "...        ...        ...                                                ...  \n",
       "31292        1          4      var jsonVariable = {};&#xD;&#xA;    for(va...  \n",
       "32204        1          4      if (data === parseInt(data, 10))&#xD;&#xA;...  \n",
       "40243        1          7      var a = {};&#xD;&#xA;    Object.defineProp...  \n",
       "48654        1          4      var arr = [1];&#xD;&#xA;    var newItems =...  \n",
       "52040        1          6      var x = {};&#xD;&#xA;    // some code wher...  \n",
       "\n",
       "[66 rows x 9 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "golden_set.loc[golden_set['PostId'].map(lambda x: x in id_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'eval'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-1460fcf842f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvalidation_metrics\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-80-023e0ff7c7f4>\u001b[0m in \u001b[0;36mvalidation_metrics\u001b[0;34m(model, valid_dl)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mvalidation_metrics\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mtp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'eval'"
     ]
    }
   ],
   "source": [
    "validation_metrics (load_model, train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
