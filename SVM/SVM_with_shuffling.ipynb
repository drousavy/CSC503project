{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTICE: I marked the places you should experiment with: # CHANGE, \n",
    "# so it should be easier to find the places to change and try different methods. \n",
    "\n",
    "# comment out these lines if you have already installed these modules\n",
    "#!pip install nltk\n",
    "#!pip install tensorflow\n",
    "#!pip install keras\n",
    "\n",
    "import sklearn as sk\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import nltk\n",
    "import tensorflow\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from pandas import DataFrame\n",
    "from matplotlib import pyplot\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sriku\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\sriku\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_news(news):\n",
    "    _news = news.replace('b\\\"', \"\")\n",
    "    _news = _news.replace('b\\'', \"\")\n",
    "    _news = _news.lower()\n",
    "    _news = re.sub(\"[^a-zA-Z]\", \" \",_news)\n",
    "    _news = re.sub('[\\s]+', ' ', _news)\n",
    "    \n",
    "    tokens = _news.split(\" \")\n",
    "    if \"\" in tokens:\n",
    "        tokens.remove(\"\")\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer() \n",
    "    tokens = [lemmatizer.lemmatize(w) for w in tokens]\n",
    "    #remove punctuation from each token\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    tokens = [w.translate(table) for w in tokens]\n",
    "    \n",
    "    # remove remaining tokens that are not alphabetic\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    # filter out stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [w for w in tokens if not w in stop_words]\n",
    "    # filter out short tokens\n",
    "    tokens = [word for word in tokens if len(word) > 1]\n",
    "    \n",
    "    _news = ' '.join(tokens)    \n",
    "     \n",
    "    return _news"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "\n",
    "    data = pd.read_csv(\"C:/Users/sriku/Downloads/CSC503project-master/CSC503project-master/Datasets/djia/Combined_News_DJIA.csv\")\n",
    "    \n",
    "    dfs = []\n",
    "    data[\"News\"] = \"\"\n",
    "    for i in range(1,25):\n",
    "        col = \"Top\"+str(i)\n",
    "        data[\"News\"] = data[\"News\"] +\" \"+ data[col]\n",
    "    data = data.dropna()\n",
    "    data['PreProcessedNews'] = data['News'].map(process_news)\n",
    "    \n",
    "    data = data[['Date', 'News', 'PreProcessedNews', 'Label']]\n",
    "    \n",
    "    stock_prices = \"C:/Users/sriku/Downloads/CSC503project-master/CSC503project-master/Datasets/djia/upload_DJIA_table.csv\"\n",
    "    stock_data = pd.read_csv(stock_prices)\n",
    "    \n",
    "    print(data.head(2))\n",
    "    print(stock_data.head(2))\n",
    "    \n",
    "    \n",
    "    #merged_dataframe = data.merge(stock_data, how='inner', on='Date')\n",
    "    merged_dataframe = pd.merge(data, stock_data, how='inner', on = 'Date')\n",
    "    from sklearn.utils import shuffle\n",
    "    for i in range(5):\n",
    "        merged_dataframe = shuffle(merged_dataframe)\n",
    "\n",
    "    Xy_train = merged_dataframe[:int(len(data)*0.8)]\n",
    "    Xy_test = merged_dataframe[int(len(data)*0.8):]\n",
    "    print(Xy_train.shape)\n",
    "    print(Xy_test.shape)\n",
    "    return merged_dataframe, Xy_train, Xy_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data function call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date                                               News  \\\n",
      "0  2008-08-08   b\"Georgia 'downs two Russian warplanes' as co...   \n",
      "1  2008-08-11   b'Why wont America and Nato help us? If they ...   \n",
      "\n",
      "                                    PreProcessedNews  Label  \n",
      "0  georgia two russian warplane country move brin...      0  \n",
      "1  wont america nato help wont help help iraq bus...      1  \n",
      "         Date          Open          High           Low         Close  \\\n",
      "0  2016-07-01  17924.240234  18002.380859  17916.910156  17949.369141   \n",
      "1  2016-06-30  17712.759766  17930.609375  17711.800781  17929.990234   \n",
      "\n",
      "      Volume     Adj Close  \n",
      "0   82160000  17949.369141  \n",
      "1  133030000  17929.990234  \n",
      "(1588, 10)\n",
      "(398, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>News</th>\n",
       "      <th>PreProcessedNews</th>\n",
       "      <th>Label</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1118</th>\n",
       "      <td>2013-01-23</td>\n",
       "      <td>$20 trillion oil basin discovered in Australi...</td>\n",
       "      <td>trillion oil basin discovered australia set tu...</td>\n",
       "      <td>1</td>\n",
       "      <td>13712.209961</td>\n",
       "      <td>13794.290039</td>\n",
       "      <td>13710.129883</td>\n",
       "      <td>13779.330078</td>\n",
       "      <td>104490000</td>\n",
       "      <td>13779.330078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>2014-05-30</td>\n",
       "      <td>India arrests police officers over gang rape ...</td>\n",
       "      <td>india arrest police officer gang rape siberian...</td>\n",
       "      <td>1</td>\n",
       "      <td>16697.330078</td>\n",
       "      <td>16721.220703</td>\n",
       "      <td>16648.849609</td>\n",
       "      <td>16717.169922</td>\n",
       "      <td>105190000</td>\n",
       "      <td>16717.169922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>b\" \\t\\n\\nUganda's 'kill gays' friends' bill: ...</td>\n",
       "      <td>nuganda kill gay friend bill nanti gay law wor...</td>\n",
       "      <td>1</td>\n",
       "      <td>10003.690430</td>\n",
       "      <td>10031.959961</td>\n",
       "      <td>9835.089844</td>\n",
       "      <td>10012.230469</td>\n",
       "      <td>308320000</td>\n",
       "      <td>10012.230469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>2009-11-05</td>\n",
       "      <td>b'We broke the law, admits CIA agent convicte...</td>\n",
       "      <td>broke law admits cia agent convicted rendition...</td>\n",
       "      <td>1</td>\n",
       "      <td>9807.799805</td>\n",
       "      <td>10013.070312</td>\n",
       "      <td>9807.799805</td>\n",
       "      <td>10005.959961</td>\n",
       "      <td>211040000</td>\n",
       "      <td>10005.959961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>2009-01-21</td>\n",
       "      <td>b'Huh? The NYTimes publishes an Op-Ed by Liby...</td>\n",
       "      <td>huh nytimes publishes op ed libyan leader muam...</td>\n",
       "      <td>1</td>\n",
       "      <td>7949.169922</td>\n",
       "      <td>8243.549805</td>\n",
       "      <td>7936.189941</td>\n",
       "      <td>8228.099609</td>\n",
       "      <td>410040000</td>\n",
       "      <td>8228.099609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date                                               News  \\\n",
       "1118  2013-01-23   $20 trillion oil basin discovered in Australi...   \n",
       "1458  2014-05-30   India arrests police officers over gang rape ...   \n",
       "374   2010-02-05   b\" \\t\\n\\nUganda's 'kill gays' friends' bill: ...   \n",
       "313   2009-11-05   b'We broke the law, admits CIA agent convicte...   \n",
       "113   2009-01-21   b'Huh? The NYTimes publishes an Op-Ed by Liby...   \n",
       "\n",
       "                                       PreProcessedNews  Label          Open  \\\n",
       "1118  trillion oil basin discovered australia set tu...      1  13712.209961   \n",
       "1458  india arrest police officer gang rape siberian...      1  16697.330078   \n",
       "374   nuganda kill gay friend bill nanti gay law wor...      1  10003.690430   \n",
       "313   broke law admits cia agent convicted rendition...      1   9807.799805   \n",
       "113   huh nytimes publishes op ed libyan leader muam...      1   7949.169922   \n",
       "\n",
       "              High           Low         Close     Volume     Adj Close  \n",
       "1118  13794.290039  13710.129883  13779.330078  104490000  13779.330078  \n",
       "1458  16721.220703  16648.849609  16717.169922  105190000  16717.169922  \n",
       "374   10031.959961   9835.089844  10012.230469  308320000  10012.230469  \n",
       "313   10013.070312   9807.799805  10005.959961  211040000  10005.959961  \n",
       "113    8243.549805   7936.189941   8228.099609  410040000   8228.099609  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news, Xy_train, Xy_test = read_data()\n",
    "news.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = Xy_train['PreProcessedNews']\n",
    "X_test = Xy_test['PreProcessedNews']\n",
    "y_train = Xy_train['Label'].to_numpy()\n",
    "y_test = Xy_test['Label'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare data for vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(train_docs, test_docs, mode):\n",
    "    # create the tokenizer\n",
    "    tokenizer = Tokenizer()\n",
    "    # fit the tokenizer on the documents\n",
    "    tokenizer.fit_on_texts(train_docs)\n",
    "    # encode training data set\n",
    "    Xtrain = tokenizer.texts_to_matrix(train_docs, mode=mode)\n",
    "    # encode testing data set\n",
    "    Xtest = tokenizer.texts_to_matrix(test_docs, mode=mode)\n",
    "    \n",
    "    return Xtrain, Xtest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create vectors for each sentence\n",
    "* binary\n",
    "* count\n",
    "* tfidf\n",
    "* freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modes = ['binary', 'count', 'tfidf', 'freq']\n",
    "\n",
    "# CHANGE MODE\n",
    "mode = 'tfidf'\n",
    "\n",
    "X_train, X_test = prepare_data(X_train, X_test, mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(398, 25781)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1588, 25781)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.00371747, 0.00371747, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.00384615, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.02295082, 0.00327869, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.0078125 , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.00743494, 0.01115242, ..., 0.00371747, 0.00371747,\n",
       "        0.00371747]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reduce the dimentionality since this is a sparse vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Make sure to comment one or the other.\n",
    "\n",
    "# CHANGE TO SVD\n",
    "# CHANGE: the n_components - Reduce dimensionality\n",
    "svd = TruncatedSVD(n_components=40, n_iter=30)\n",
    "X_train = svd.fit_transform(X_train)\n",
    "X_test = svd.transform(X_test)\n",
    "\n",
    "# # CHANGE TO PCA\n",
    "# # CHANGE: the the n_components - Reduce dimensionality\n",
    "# pca = PCA(n_components=2)\n",
    "# X_train = pca.fit_transform(X_train)\n",
    "# X_test = pca.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1588, 40)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(398, 40)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply machine learning example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for accuracy\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 1e-05, 'kernel': 'linear'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.536 (+/-0.002) for {'C': 1e-05, 'kernel': 'linear'}\n",
      "0.536 (+/-0.002) for {'C': 0.0001, 'kernel': 'linear'}\n",
      "0.536 (+/-0.002) for {'C': 0.001, 'kernel': 'linear'}\n",
      "0.517 (+/-0.037) for {'C': 0.01, 'kernel': 'linear'}\n",
      "0.503 (+/-0.022) for {'C': 0.1, 'kernel': 'linear'}\n",
      "0.499 (+/-0.018) for {'C': 1, 'kernel': 'linear'}\n",
      "0.502 (+/-0.017) for {'C': 2, 'kernel': 'linear'}\n",
      "0.503 (+/-0.019) for {'C': 3, 'kernel': 'linear'}\n",
      "0.502 (+/-0.020) for {'C': 4, 'kernel': 'linear'}\n",
      "0.502 (+/-0.020) for {'C': 5, 'kernel': 'linear'}\n",
      "0.502 (+/-0.020) for {'C': 6, 'kernel': 'linear'}\n",
      "0.501 (+/-0.016) for {'C': 7, 'kernel': 'linear'}\n",
      "0.501 (+/-0.022) for {'C': 8, 'kernel': 'linear'}\n",
      "0.502 (+/-0.021) for {'C': 9, 'kernel': 'linear'}\n",
      "0.503 (+/-0.019) for {'C': 10, 'kernel': 'linear'}\n",
      "0.502 (+/-0.020) for {'C': 20, 'kernel': 'linear'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       187\n",
      "           1       0.53      1.00      0.69       211\n",
      "\n",
      "    accuracy                           0.53       398\n",
      "   macro avg       0.27      0.50      0.35       398\n",
      "weighted avg       0.28      0.53      0.37       398\n",
      "\n",
      "[[  0 187]\n",
      " [  0 211]]\n",
      "\n",
      "# Tuning hyper-parameters for precision\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sriku\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sriku\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sriku\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sriku\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sriku\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sriku\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sriku\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sriku\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sriku\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sriku\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sriku\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sriku\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sriku\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sriku\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sriku\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sriku\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sriku\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sriku\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 0.01, 'kernel': 'linear'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.268 (+/-0.001) for {'C': 1e-05, 'kernel': 'linear'}\n",
      "0.268 (+/-0.001) for {'C': 0.0001, 'kernel': 'linear'}\n",
      "0.268 (+/-0.001) for {'C': 0.001, 'kernel': 'linear'}\n",
      "0.492 (+/-0.054) for {'C': 0.01, 'kernel': 'linear'}\n",
      "0.487 (+/-0.029) for {'C': 0.1, 'kernel': 'linear'}\n",
      "0.483 (+/-0.024) for {'C': 1, 'kernel': 'linear'}\n",
      "0.486 (+/-0.024) for {'C': 2, 'kernel': 'linear'}\n",
      "0.486 (+/-0.026) for {'C': 3, 'kernel': 'linear'}\n",
      "0.485 (+/-0.028) for {'C': 4, 'kernel': 'linear'}\n",
      "0.485 (+/-0.028) for {'C': 5, 'kernel': 'linear'}\n",
      "0.485 (+/-0.028) for {'C': 6, 'kernel': 'linear'}\n",
      "0.484 (+/-0.024) for {'C': 7, 'kernel': 'linear'}\n",
      "0.485 (+/-0.030) for {'C': 8, 'kernel': 'linear'}\n",
      "0.486 (+/-0.028) for {'C': 9, 'kernel': 'linear'}\n",
      "0.486 (+/-0.026) for {'C': 10, 'kernel': 'linear'}\n",
      "0.485 (+/-0.028) for {'C': 20, 'kernel': 'linear'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.10      0.16       187\n",
      "           1       0.53      0.89      0.66       211\n",
      "\n",
      "    accuracy                           0.52       398\n",
      "   macro avg       0.48      0.49      0.41       398\n",
      "weighted avg       0.49      0.52      0.43       398\n",
      "\n",
      "[[ 18 169]\n",
      " [ 23 188]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score\n",
    "from sklearn.svm import SVC\n",
    "import warnings\n",
    "warnings.filterwarnings('always')  # \"error\", \"ignore\", \"always\", \"default\", \"module\" or \"once\"\n",
    "\n",
    "# Please refer to:\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "# for more information of which parameters to change for each kernel\n",
    "\n",
    "# CHANGE: Set the parameters by cross-validation\n",
    "tuned_parameters = [\n",
    "#{'kernel': ['rbf'], 'gamma': [1e-1, 1e-2, 1e-3, 1e-4, 1e-5],'C': [0.00001,0.0001,0.001,0.01,0.1,1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 20]},\n",
    "\n",
    "# {'kernel': ['sigmoid'], 'gamma': [1e-0,1e-1, 1e-2, 1e-3, 1e-4, 1e-5, 1e-6, 1e-7, 1e-8, 1e-9],'C': [0.00001,0.0001,0.001,0.01,0.1,1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 20]},\n",
    "\n",
    "# {'kernel': ['poly'], 'gamma': [1e-1, 1e-2, 1e-3, 1e-4, 1e-5], 'C': [0.00001,0.0001,0.001,0.01,0.1,1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 20], \n",
    "# 'degree': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]},\n",
    " \n",
    "{'kernel': ['linear'], 'C': [0.00001,0.0001,0.001,0.01,0.1,1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 20]}\n",
    "\n",
    "]\n",
    "\n",
    "scores = ['accuracy', 'precision']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "    \n",
    "    if score == \"accuracy\":\n",
    "    \n",
    "        clf = GridSearchCV(\n",
    "            SVC(), tuned_parameters, scoring=score\n",
    "        )\n",
    "    \n",
    "    if score == \"precision\":\n",
    "        clf = GridSearchCV(\n",
    "            SVC(), tuned_parameters, scoring='%s_macro' % score\n",
    "        )\n",
    "    \n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print(confusion_matrix(y_true,y_pred))\n",
    "    print()\n",
    "\n",
    "# Note the problem is too easy: the hyperparameter plateau is too flat and the\n",
    "# output model is the same for precision and recall with ties in quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],'C': [50, 100, 150, 200]},\n",
    "\n",
    "# {'kernel': ['sigmoid'], 'gamma': [1e-0,1e-1, 1e-2, 1e-3, 1e-4, 1e-5, 1e-6, 1e-7, 1e-8, 1e-9],'C': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 20, 50]},\n",
    "\n",
    "# {'kernel': ['poly'], 'gamma': [1e-1, 1e-2, 1e-3, 1e-4, 1e-5], 'C': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 20], \n",
    "# 'degree': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]},\n",
    " \n",
    "# {'kernel': ['linear'], 'C': [50, 100, 150, 200]\n",
    "    \n",
    "# {'kernel': ['rbf'], 'gamma': [1e-2,1e-1, 1,1e+1,1e+2],'C': np.logspace(-2,2,5)},\n",
    "\n",
    "# {'kernel': ['sigmoid'], 'gamma': np.logspace(-2,2,5),'C': np.logspace(-2,2,5)},\n",
    "\n",
    "# #{'kernel': ['poly'], 'gamma': np.logspace(-2,2,5), 'C': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 20], \n",
    "# #'degree': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]},\n",
    " \n",
    "# {'kernel': ['linear'], 'C': np.logspace(-2,2,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### OLD RESULTS - BEFORE SHUFFLING ######\n",
    "##### P.S : No shuffling, so results will just be the same anytime your run the code #######\n",
    "# mode = binary\n",
    "\n",
    "# training first 80%, testing last 20%, n_components = 20 : {'C': 0.001, 'kernel': 'linear'} - 0.51\n",
    "# training last 20%, testing first 80% : {'C': 1e-05, 'kernel': 'linear'} - 0.52 \n",
    "# training first 70%, testing last 30% : {'C': 1e-05, 'kernel': 'linear'} - 0.53\n",
    "# training first 60%, testing last 40% : {'C': 1e-05, 'kernel': 'linear'} - 0.53\n",
    "\n",
    "# 70/30 {'C': 0.01, 'degree': 7, 'gamma': 0.1, 'kernel': 'poly'} - 0.53\n",
    "\n",
    "# 50/50 sigmoid - 0.54\n",
    "\n",
    "# mode = tfidf\n",
    "# 50/50 {'C': 1e-05, 'kernel': 'linear'} - 0.54"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### NEW RESULTS - UPON SHUFFLING ######\n",
    "##### P.S : Because we are shuffling the data, the below results will keep changing #####\n",
    "# shuffle merged dataframe = 5 times\n",
    "# svc : n_components = 40, iter = 30\n",
    "\n",
    "# mode = binary\n",
    "# 80/20 , {'C': 1e-05, 'kernel': 'linear'} - 0.53 accuracy\n",
    "# 80/20 , {'C': 4, 'kernel': 'linear'} - 0.54 precision\n",
    "\n",
    "# mode = count\n",
    "# 80/20 , {'C': 1e-05, 'kernel': 'linear'} - 0.50\n",
    "\n",
    "# mode = tfidf\n",
    "# 80/20, {'C': 1e-05, 'kernel': 'linear'} - 0.55 accuracy\n",
    "# 80/20, {'C': 0.01, 'kernel': 'linear'} - 0.56 precision"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
