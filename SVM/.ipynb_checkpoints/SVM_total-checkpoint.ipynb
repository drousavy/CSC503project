{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comment out these lines if you have already installed these modules\n",
    "#!pip install nltk\n",
    "#!pip install tensorflow\n",
    "#!pip install keras\n",
    "\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "import sklearn as sk\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import nltk\n",
    "# nltk.download()\n",
    "import tensorflow\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from pandas import DataFrame\n",
    "from matplotlib import pyplot\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_news(news):\n",
    "    _news = news.replace('b\\\"', \"\")\n",
    "    _news = _news.replace('b\\'', \"\")\n",
    "    _news = _news.lower()\n",
    "    _news = re.sub(\"[^a-zA-Z]\", \" \",_news)\n",
    "    _news = re.sub('[\\s]+', ' ', _news)\n",
    "    \n",
    "    tokens = _news.split(\" \")\n",
    "    if \"\" in tokens:\n",
    "        tokens.remove(\"\")\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer() \n",
    "    tokens = [lemmatizer.lemmatize(w) for w in tokens]\n",
    "    #remove punctuation from each token\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    tokens = [w.translate(table) for w in tokens]\n",
    "    \n",
    "    # remove remaining tokens that are not alphabetic\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    # filter out stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [w for w in tokens if not w in stop_words]\n",
    "    # filter out short tokens\n",
    "    tokens = [word for word in tokens if len(word) > 1]\n",
    "    \n",
    "    _news = ' '.join(tokens)    \n",
    "     \n",
    "    return _news"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "\n",
    "    data = pd.read_csv(\"../Datasets/djia/Combined_News_DJIA.csv\")\n",
    "    \n",
    "    dfs = []\n",
    "    data[\"News\"] = \"\"\n",
    "    for i in range(1,25):\n",
    "        col = \"Top\"+str(i)\n",
    "        data[\"News\"] = data[\"News\"] +\" \"+ data[col]\n",
    "    data = data.dropna()\n",
    "    data['PreProcessedNews'] = data['News'].map(process_news)\n",
    "    \n",
    "    data = data[['Date', 'News', 'PreProcessedNews', 'Label']]\n",
    "    \n",
    "    stock_prices = \"../Datasets/djia/upload_DJIA_table.csv\"\n",
    "    stock_data = pd.read_csv(stock_prices)\n",
    "    \n",
    "    print(data.head(2))\n",
    "    print(stock_data.head(2))\n",
    "    \n",
    "    \n",
    "    #merged_dataframe = data.merge(stock_data, how='inner', on='Date')\n",
    "    merged_dataframe = pd.merge(data, stock_data, how='inner', on = 'Date')\n",
    "\n",
    "    Xy_train = merged_dataframe[:int(len(data)*0.8)]\n",
    "#     Xy_valid = merged_dataframe[int(len(data)*0.6):int(len(data)*0.8)]\n",
    "    Xy_test = merged_dataframe[int(len(data)*0.8):]\n",
    "    \n",
    "    \n",
    "#     Xy_train = merged_dataframe[:int(len(data)*0.6)]\n",
    "#     Xy_valid = merged_dataframe[int(len(data)*0.6):int(len(data)*0.8)]\n",
    "#     Xy_test = merged_dataframe[int(len(data)*0.8):]\n",
    "    \n",
    "    return merged_dataframe, Xy_train, Xy_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data function call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news, Xy_train, Xy_test = read_data()\n",
    "\n",
    "\n",
    "# news, Xy_train, Xy_valid, Xy_test = read_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = Xy_train['PreProcessedNews']\n",
    "# X_valid = Xy_valid['PreProcessedNews']\n",
    "X_test = Xy_test['PreProcessedNews']\n",
    "y_train = Xy_train['Label'].to_numpy()\n",
    "# y_valid = Xy_valid['Label'].to_numpy()\n",
    "y_test = Xy_test['Label'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare data for vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def prepare_data(train_docs, valid_docs, test_docs, mode):\n",
    "    \n",
    "def prepare_data(train_docs, test_docs, mode):\n",
    "    # create the tokenizer\n",
    "    tokenizer = Tokenizer()\n",
    "    # fit the tokenizer on the documents\n",
    "    tokenizer.fit_on_texts(train_docs)\n",
    "    # encode training data set\n",
    "    Xtrain = tokenizer.texts_to_matrix(train_docs, mode=mode)\n",
    "    \n",
    "#     # encode training data set\n",
    "#     Xvalid = tokenizer.texts_to_matrix(valid_docs, mode=mode)\n",
    "    \n",
    "    \n",
    "    # encode testing data set\n",
    "    Xtest = tokenizer.texts_to_matrix(test_docs, mode=mode)\n",
    "    \n",
    "    \n",
    "    return Xtrain, Xtest\n",
    "\n",
    "#     return Xtrain, Xvalid, Xtest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create vectors for each sentence\n",
    "* binary\n",
    "* count\n",
    "* tfidf\n",
    "* freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modes = ['binary', 'count', 'tfidf', 'freq']\n",
    "\n",
    "#CHANGE MODE\n",
    "mode = 'binary'\n",
    "\n",
    "X_train, X_test = prepare_data(X_train, X_test, mode)\n",
    "\n",
    "# X_train, X_valid, X_test = prepare_data(X_train, X_valid, X_test, mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reduce the dimentionality since this is a sparse vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# CHANGE TO PCA\n",
    "# Reduce dimensionality: Change the n_components\n",
    "svd = TruncatedSVD(n_components=50, n_iter=10)\n",
    "X_train = svd.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_valid = svd.transform(X_valid)\n",
    "X_test = svd.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply machine learning example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fitting Kernel SVM to the Training set\n",
    "# from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "# # kernel{‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’}, default=’rbf’\n",
    "# # Cfloat, default=1.0\n",
    "# # degreeint, default=3\n",
    "# # gamma{‘scale’, ‘auto’} or float, default=’scale’, Kernel coefficient for ‘rbf’, ‘poly’ and ‘sigmoid’.\n",
    "# # coef0float, default=0.0\n",
    "\n",
    "# classifier = SVC(kernel = 'rbf', C=1, random_state = 0)\n",
    "# classifier.fit(X_train, y_train)\n",
    "\n",
    "# # Predicting the Test set results\n",
    "# y_pred = classifier.predict(X_test)\n",
    "\n",
    "# # Making the Confusion Matrix\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# cm = confusion_matrix(y_test, y_pred)\n",
    "# # print(\"confusion matrix\", cm)\n",
    "\n",
    "\n",
    "# # Applying k-Fold Cross Validation\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# train_accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "# accuracy_mean = accuracies.mean()\n",
    "# accuracy_std = accuracies.std()\n",
    "\n",
    "# # Test Accuracy\n",
    "# test_acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "# print(classifier)\n",
    "# # print(accuracies)\n",
    "# # print(accuracy_std)\n",
    "# print(\"Training Accuracy\", accuracy_mean)\n",
    "# print(\"Testing Accuracy\", test_acc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Setting up Grid Search\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# # grid_param = {\n",
    "# #     'C': [1, 2, 3, 4, 5],\n",
    "# #     'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "# #     'gamma': [0.1, 0.01, 0.001]\n",
    "# # }\n",
    "\n",
    "# grid_param =  [ \n",
    "# {'C': [1, 2, 3], 'kernel': ['linear']},\n",
    "# {'C': [1, 2, 3], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']},\n",
    "\n",
    "# ]\n",
    "\n",
    "\n",
    "# gd_sr = GridSearchCV(estimator=classifier,\n",
    "#                      param_grid=grid_param,\n",
    "#                      scoring='accuracy',\n",
    "#                      cv=10,\n",
    "#                      n_jobs=-1)\n",
    "\n",
    "# gd_sr.fit(X_train, y_train)\n",
    "\n",
    "# best_parameters = gd_sr.best_params_\n",
    "# print(best_parameters)\n",
    "\n",
    "# best_result = gd_sr.best_score_\n",
    "# print(best_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "import warnings\n",
    "warnings.filterwarnings('always')  # \"error\", \"ignore\", \"always\", \"default\", \"module\" or \"once\"\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [\n",
    "{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],'C': [50, 100, 150, 200]},\n",
    "\n",
    "{'kernel': ['sigmoid'], 'gamma': [1e-3, 1e-4],'C': [50, 100, 150, 200]},\n",
    "{'kernel': ['poly'], 'gamma': [1e-3, 1e-4], 'C': [50, 100, 150, 200], \n",
    "'degree': [1, 2, 3, 4, 5, 6, 7, 8]},\n",
    " \n",
    "{'kernel': ['linear'], 'C': [50, 100, 150, 200]}\n",
    "\n",
    "]\n",
    "\n",
    "scores = ['precision', 'recall']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "    \n",
    "\n",
    "    clf = GridSearchCV(\n",
    "        SVC(), tuned_parameters, scoring='%s_macro' % score\n",
    "    )\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()\n",
    "\n",
    "# Note the problem is too easy: the hyperparameter plateau is too flat and the\n",
    "# output model is the same for precision and recall with ties in quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
